{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio \n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.cuda.device_count()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5  # number of  nodes\n",
    "\n",
    "learning_rate = 0.001  # learning rate\n",
    "\n",
    "batch_size = 1000\n",
    "n_batch = 100\n",
    "n_epoch = 1000  # number of iterations\n",
    "n_val = 10000   # number of validation data\n",
    "n_test = 10000\n",
    "\n",
    "mode = 'mlp'\n",
    "\n",
    "if mode == 'mlp':\n",
    "    n_hidden = 1000\n",
    "    n_layer = 10\n",
    "    T = 1\n",
    "    model_location = \"./UL_MLP_N%d_(nH%d,nL%d)\" % (N, n_hidden, n_layer)\n",
    "elif mode == 'cnn':\n",
    "    n_kernel = 200\n",
    "    T = 5\n",
    "    model_location = \"./UL_CNN_N%d_(nK%d, T%d)\" % (N, n_kernel, T)\n",
    "    \n",
    "if not os.path.isdir(model_location): os.mkdir(model_location)\n",
    "    \n",
    "fw = 1-torch.eye(N).unsqueeze(2).tile(1, 1, N).to(device)\n",
    "gw = 1-torch.eye(N).unsqueeze(1).tile(1, N, 1).to(device)\n",
    "window = {'a': fw, 'r': gw}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_hidden, n_layers):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        layers = [nn.BatchNorm1d(N**2), nn.Linear(N**2, n_hidden), nn.BatchNorm1d(n_hidden), nn.SELU()]\n",
    "        \n",
    "        for i in range(n_layer-2):\n",
    "            layers.append(nn.Linear(n_hidden, n_hidden))\n",
    "            layers.append(nn.BatchNorm1d(n_hidden))\n",
    "            layers.append(nn.SELU())\n",
    "            \n",
    "        layers.append(nn.Linear(n_hidden, 2*N**2))\n",
    "        #layers.append(nn.BatchNorm1d(2*N**2))\n",
    "        #layers.append(nn.Tanh())\n",
    "                                      \n",
    "        self.layers = nn.Sequential(*layers)\n",
    "                                       \n",
    "    def forward(self, x, C):\n",
    "        x = self.layers(x)\n",
    "        #x = torch.max(torch.abs(C).view(-1, N**2), 1).values.unsqueeze(1)*x\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv = nn.ModuleList([self.layer(t) for t in range(2*T)])\n",
    "\n",
    "    def layer(self, t):\n",
    "        if t%2 == 0:\n",
    "            conv0 = nn.Conv2d(2, 1, (N, 1))\n",
    "        else:\n",
    "            conv0 = nn.Conv2d(2, 1, (1, N))\n",
    "        conv1 = nn.Sequential(nn.Conv2d(3, n_kernel, 1), nn.BatchNorm2d(n_kernel), nn.ReLU(),\n",
    "                              nn.Conv2d(n_kernel, n_kernel, 1), nn.ReLU(),\n",
    "                              nn.Conv2d(n_kernel, 1, 1), nn.ReLU())\n",
    "        conv2 = nn.Sequential(nn.Conv2d(3, n_kernel, 1), nn.BatchNorm2d(n_kernel), nn.ReLU(),\n",
    "                              nn.Conv2d(n_kernel, n_kernel, 1), nn.ReLU(),\n",
    "                              nn.Conv2d(n_kernel, 1, 1))\n",
    "        return nn.ModuleList([conv0, conv1, conv2])\n",
    "        \n",
    "    def module(self, x, y, C, layer, name_scope):\n",
    "        if name_scope == 'r':\n",
    "            x_init = layer[0](torch.cat([C, y], 1)).tile(1, 1, N, 1)\n",
    "        elif name_scope == 'a':\n",
    "            x_init = layer[0](torch.cat([C, y], 1)).tile(1, 1, 1, N)\n",
    "        x = layer[1](torch.cat([C, x, x_init], 1)).reshape(-1, 1, N, N)\n",
    "        x = torch.where(window[name_scope] == 0.0, torch.tensor([-10000.0]).to(device), x)\n",
    "        if name_scope == 'r':\n",
    "            x = layer[2](torch.cat([C, torch.max(x, 2).values.unsqueeze(1), x_init], 1))\n",
    "        elif name_scope == 'a':\n",
    "            x = layer[2](torch.cat([C, torch.max(x, 3).values.permute(0, 2, 1).unsqueeze(1), x_init], 1))\n",
    "        #x = torch.max(torch.abs(C).reshape(-1, N**2), 1).values.unsqueeze(1).unsqueeze(2).unsqueeze(3)*x\n",
    "        #Cmax = torch.max(torch.abs(C).reshape(-1, N**2), 1).values.reshape(-1, 1, 1, 1)\n",
    "        #x = torch.maximum(torch.minimum(x, Cmax), -Cmax)\n",
    "        return x\n",
    "                                               \n",
    "    def forward(self, C):\n",
    "        \n",
    "        x = torch.zeros(C.shape[0], N, N, 2, T).to(device)\n",
    "        a, r = C, C\n",
    "        \n",
    "        for t in range(0, 2*T, 2):\n",
    "            \n",
    "            r = self.module(a, r, C, self.conv[t], 'r')\n",
    "            a = self.module(r, a, C, self.conv[t+1], 'a')\n",
    "            \n",
    "            x[:, :, :, :, int(t/2)] = torch.stack([r.squeeze(), a.squeeze()], 3)\n",
    "\n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == 'mlp':\n",
    "    model = MLP(n_hidden, n_layer).to(device)\n",
    "elif mode == 'cnn':\n",
    "    model = CNN().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeStatistics(y, C):\n",
    "    ff = (y[:, :, :, 1] + C/2).unsqueeze(1).tile(1, N, 1, 1)\n",
    "    gg = (y[:, :, :, 0] + C/2).unsqueeze(1).tile(1, N, 1, 1)\n",
    "\n",
    "    ff = torch.where(fw == 0.0, torch.tensor([-10000.0]).to(device), ff)\n",
    "    gg = torch.where(gw == 0.0, torch.tensor([-10000.0]).to(device), gg)\n",
    "       \n",
    "    f = C/2 - torch.max(ff, 2).values \n",
    "    g = C/2 - torch.max(gg, 3).values.permute(0, 2, 1)\n",
    "\n",
    "    return f, g\n",
    "\n",
    "def computeCost(y, C):\n",
    "    x = torch.max(y[:, :, :, 0] + y[:, :, :, 1], 1).indices\n",
    "    x_one_hot = F.one_hot(x, num_classes=N)\n",
    "    cost = (C*x_one_hot.permute(0, 2, 1)).sum()/y.shape[0]\n",
    "    \n",
    "    return x, x_one_hot, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_val = torch.from_numpy(np.random.exponential(scale=1, size=(n_val, N, N))).float().to(device)\n",
    "c_val = 1000000.0\n",
    "cost_eval = np.zeros((n_epoch, 4))\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in range(n_batch):\n",
    "        \n",
    "        #C_train = torch.rand(batch_size, N, N).to(device)\n",
    "        C_train = torch.from_numpy(np.random.exponential(scale=1, size=(n_batch, N, N))).float().to(device)\n",
    "        \n",
    "        if mode == 'mlp':\n",
    "            y = model(torch.reshape(C_train, (-1, N**2)), C_train).reshape(-1, N, N, 2, 1)\n",
    "        elif mode == 'cnn':\n",
    "            y = model(C_train.unsqueeze(1))\n",
    "            \n",
    "        loss = 0.0\n",
    "        for t in range(T):\n",
    "            yt = y[:, :, :, :, t]\n",
    "            f, g = computeStatistics(yt, C_train)\n",
    "            loss += loss_fn(yt, torch.stack([f, g], dim=3))/T\n",
    "        \n",
    "        _, _, cost_train = computeCost(yt, C_train)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        cost_eval[epoch, 0] += loss.item()/n_batch\n",
    "        cost_eval[epoch, 2] += cost_train/n_batch\n",
    "        \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        if mode == 'mlp':\n",
    "            y_val = model(torch.reshape(C_val, (-1, N**2)), C_val).reshape(-1, N, N, 2, 1)\n",
    "        elif mode == 'cnn':\n",
    "            y_val = model(C_val.unsqueeze(1))\n",
    "            \n",
    "        for t in range(T):\n",
    "            yt_val = y_val[:, :, :, :, t]\n",
    "            f_val, g_val = computeStatistics(yt_val, C_val)\n",
    "            cost_eval[epoch, 1] += loss_fn(yt_val, torch.stack([f_val, g_val], dim=3)).item()/T\n",
    "        #f_val, g_val = computeStatistics(y_val, C_val)\n",
    "        #cost_eval[epoch, 1] = loss_fn(y_val, torch.stack([f_val, g_val], dim=3)).item()\n",
    "        \n",
    "        x_val, _, cost_val = computeCost(yt_val, C_val)\n",
    "        cost_eval[epoch, 3] += cost_val\n",
    "        \n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        print('epoch:%d ' % (epoch + 1),\\\n",
    "              'train MSE:%0.5f, ' % cost_eval[epoch, 0],\\\n",
    "              'validation MSE:%0.5f, ' % cost_eval[epoch, 1],\\\n",
    "              'train COST: %0.5f, ' % cost_eval[epoch, 2],\\\n",
    "              'validation COST:%0.5f, ' % cost_eval[epoch, 3])\n",
    "        \n",
    "    if cost_eval[epoch, 1] < c_val:\n",
    "        print('Best validation MSE:%0.5f at epoch %d' % (cost_eval[epoch, 1], epoch + 1),\\\n",
    "              '(train MSE:%0.5f)' % cost_eval[epoch, 0])\n",
    "        c_val = cost_eval[epoch, 1]\n",
    "        save_dict = {'model': model.state_dict()}\n",
    "        torch.save(save_dict, model_location + \"/model.pth\")\n",
    "\n",
    "sio.savemat(model_location+\"/result.mat\", \\\n",
    "            {'trainMSE': cost_eval[:, 0], 'validationMSE': cost_eval[:, 1], \\\n",
    "             'trainCOST': cost_eval[:, 2], 'validationCOST': cost_eval[:, 3]})\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 0.056223221123218536, Test Cost: 10.175226211547852\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(170835)\n",
    "C_test = torch.from_numpy(np.random.exponential(scale=1, size=(n_test, N, N))).float().to(device)\n",
    "\n",
    "checkpoint = torch.load(model_location+'/model.pth')\n",
    "\n",
    "if mode == 'mlp':\n",
    "    model = MLP(n_hidden, n_layer).to(device)\n",
    "elif mode == 'cnn':\n",
    "    model = CNN().to(device)\n",
    "    \n",
    "model.load_state_dict(checkpoint['model'])\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    if mode == 'mlp':\n",
    "        y_test = model(torch.reshape(C_test, (-1, N**2)), C_test).reshape(-1, N, N, 2, 1)\n",
    "    elif mode == 'cnn':\n",
    "        y_test = model(C_test.unsqueeze(1))\n",
    "        \n",
    "    f_test, g_test = computeStatistics(y_test[:, :, :, :, -1], C_test)\n",
    "    loss_test = loss_fn(y_test[:, :, :, :, -1], torch.stack([f_test, g_test], dim=3)).item()\n",
    "        \n",
    "    x_test, x_test_one_hot, cost_test = computeCost(y_test[:, :, :, :, -1], C_test)\n",
    "\n",
    "print(f'Test MSE: {loss_test}, Test Cost: {cost_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5103999999999601\n"
     ]
    }
   ],
   "source": [
    "infeasible_ratio = 0\n",
    "\n",
    "for i in range(n_test):\n",
    "    if torch.unique(x_test[i, :]).shape[0] < N:\n",
    "        infeasible_ratio += 1/n_test\n",
    "    \n",
    "print(infeasible_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 0, 2, 4, 0], device='cuda:0')\n",
      "tensor([4, 4, 2, 0, 3], device='cuda:0')\n",
      "tensor([[-4.4675e+00, -2.5561e+00, -2.4517e+00,  9.6333e-01, -1.7470e+00],\n",
      "        [ 5.7526e-02, -1.2051e+00, -1.8346e+00, -2.6447e+00,  4.6558e-02],\n",
      "        [-2.8331e+00, -1.9017e+00,  1.0758e-01, -2.7167e+00, -5.6163e-01],\n",
      "        [-2.9648e+00,  9.9970e-04, -1.6046e+00, -1.1874e+00,  7.3278e-02],\n",
      "        [ 2.8570e-01,  1.0269e-01, -2.0164e+00, -2.4621e+00, -1.3240e+00]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "yy = y_test[0, :, :, 0, -1] + y_test[0, :, :, 1, -1]\n",
    "print(torch.max(yy, 1).indices)\n",
    "print(torch.max(yy, 0).indices)\n",
    "print(yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4, 4, 2, 0, 3], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(x_test[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (5) must match the size of tensor b (10000) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-a38b41d5c29a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mC_test\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mgg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mC_test\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfw\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m10000.0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mff\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mgg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgw\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m10000.0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (5) must match the size of tensor b (10000) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "ff = (y_test[:, :, :, 1] + C_test/2).unsqueeze(1).tile(1, N, 1, 1)\n",
    "gg = (y_test[:, :, :, 0] + C_test/2).unsqueeze(1).tile(1, N, 1, 1)\n",
    "\n",
    "ff = torch.where(fw == 0.0, torch.tensor([-10000.0]).to(device), ff)\n",
    "gg = torch.where(gw == 0.0, torch.tensor([-10000.0]).to(device), gg)\n",
    "       \n",
    "f = C_test/2 - torch.max(ff, 2).values \n",
    "g = C_test/2 - torch.max(gg, 3).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.max(C_train.view(-1, N**2), 1).values.unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "570feb405e2e27c949193ac68f46852414290d515b0ba6e5d90d076ed2284471"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
