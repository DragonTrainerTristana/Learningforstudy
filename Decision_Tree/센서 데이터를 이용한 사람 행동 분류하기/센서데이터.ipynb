{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/2021-ml-p10/Feature_engineering.py\n/kaggle/input/2021-ml-p10/activity_labels.txt\n/kaggle/input/2021-ml-p10/features_info.txt\n/kaggle/input/2021-ml-p10/data_loader.py\n/kaggle/input/2021-ml-p10/features.txt\n/kaggle/input/2021-ml-p10/sample_submit.csv\n/kaggle/input/2021-ml-p10/RawData/acc_exp28_user14.txt\n/kaggle/input/2021-ml-p10/RawData/acc_exp45_user22.txt\n/kaggle/input/2021-ml-p10/RawData/acc_exp15_user08.txt\n/kaggle/input/2021-ml-p10/RawData/acc_exp05_user03.txt\n/kaggle/input/2021-ml-p10/RawData/gyro_exp13_user07.txt\n/kaggle/input/2021-ml-p10/RawData/acc_exp43_user21.txt\n/kaggle/input/2021-ml-p10/RawData/acc_exp11_user06.txt\n/kaggle/input/2021-ml-p10/RawData/gyro_exp26_user13.txt\n/kaggle/input/2021-ml-p10/RawData/acc_exp39_user19.txt\n/kaggle/input/2021-ml-p10/RawData/gyro_exp05_user03.txt\n/kaggle/input/2021-ml-p10/RawData/label_train.txt\n/kaggle/input/2021-ml-p10/RawData/acc_exp13_user07.txt\n/kaggle/input/2021-ml-p10/RawData/gyro_exp54_user27.txt\n/kaggle/input/2021-ml-p10/RawData/gyro_exp40_user20.txt\n/kaggle/input/2021-ml-p10/RawData/acc_exp61_user30.txt\n/kaggle/input/2021-ml-p10/RawData/gyro_exp32_user16.txt\n/kaggle/input/2021-ml-p10/RawData/gyro_exp38_user19.txt\n/kaggle/input/2021-ml-p10/RawData/acc_exp35_user17.txt\n/kaggle/input/2021-ml-p10/RawData/gyro_exp18_user09.txt\n/kaggle/input/2021-ml-p10/RawData/acc_exp23_user11.txt\n/kaggle/input/2021-ml-p10/RawData/gyro_exp59_user29.txt\n/kaggle/input/2021-ml-p10/RawData/gyro_exp19_user10.txt\n/kaggle/input/2021-ml-p10/RawData/gyro_exp46_user23.txt\n/kaggle/input/2021-ml-p10/RawData/acc_exp41_user20.txt\n/kaggle/input/2021-ml-p10/RawData/gyro_exp17_user09.txt\n/kaggle/input/2021-ml-p10/RawData/gyro_exp28_user14.txt\n/kaggle/input/2021-ml-p10/RawData/gyro_exp29_user14.txt\n/kaggle/input/2021-ml-p10/RawData/gyro_exp50_user25.txt\n/kaggle/input/2021-ml-p10/RawData/gyro_exp11_user06.txt\n/kaggle/input/2021-ml-p10/RawData/acc_exp06_user03.txt\n/kaggle/input/2021-ml-p10/RawData/acc_exp26_user13.txt\n/kaggle/input/2021-ml-p10/RawData/gyro_exp44_user22.txt\n/kaggle/input/2021-ml-p10/RawData/gyro_exp60_user30.txt\n/kaggle/input/2021-ml-p10/RawData/gyro_exp36_user18.txt\n/kaggle/input/2021-ml-p10/RawData/acc_exp60_user30.txt\n/kaggle/input/2021-ml-p10/RawData/acc_exp46_user23.txt\n/kaggle/input/2021-ml-p10/RawData/gyro_exp45_user22.txt\n/kaggle/input/2021-ml-p10/RawData/acc_exp18_user09.txt\n/kaggle/input/2021-ml-p10/RawData/acc_exp08_user04.txt\n/kaggle/input/2021-ml-p10/RawData/acc_exp49_user24.txt\n/kaggle/input/2021-ml-p10/RawData/gyro_exp06_user03.txt\n/kaggle/input/2021-ml-p10/RawData/gyro_exp42_user21.txt\n/kaggle/input/2021-ml-p10/RawData/acc_exp37_user18.txt\n/kaggle/input/2021-ml-p10/RawData/acc_exp50_user25.txt\n/kaggle/input/2021-ml-p10/RawData/acc_exp40_user20.txt\n/kaggle/input/2021-ml-p10/RawData/acc_exp32_user16.txt\n/kaggle/input/2021-ml-p10/RawData/gyro_exp53_user26.txt\n/kaggle/input/2021-ml-p10/RawData/acc_exp52_user26.txt\n/kaggle/input/2021-ml-p10/RawData/gyro_exp27_user13.txt\n/kaggle/input/2021-ml-p10/RawData/gyro_exp52_user26.txt\n/kaggle/input/2021-ml-p10/RawData/acc_exp01_user01.txt\n/kaggle/input/2021-ml-p10/RawData/acc_exp12_user06.txt\n/kaggle/input/2021-ml-p10/RawData/acc_exp44_user22.txt\n/kaggle/input/2021-ml-p10/RawData/acc_exp09_user05.txt\n/kaggle/input/2021-ml-p10/RawData/label_test.txt\n/kaggle/input/2021-ml-p10/RawData/gyro_exp01_user01.txt\n/kaggle/input/2021-ml-p10/RawData/acc_exp27_user13.txt\n/kaggle/input/2021-ml-p10/RawData/acc_exp59_user29.txt\n/kaggle/input/2021-ml-p10/RawData/gyro_exp49_user24.txt\n/kaggle/input/2021-ml-p10/RawData/gyro_exp51_user25.txt\n/kaggle/input/2021-ml-p10/RawData/acc_exp21_user10.txt\n/kaggle/input/2021-ml-p10/RawData/gyro_exp20_user10.txt\n/kaggle/input/2021-ml-p10/RawData/gyro_exp25_user12.txt\n/kaggle/input/2021-ml-p10/RawData/gyro_exp12_user06.txt\n/kaggle/input/2021-ml-p10/RawData/acc_exp55_user27.txt\n/kaggle/input/2021-ml-p10/RawData/gyro_exp23_user11.txt\n/kaggle/input/2021-ml-p10/RawData/acc_exp24_user12.txt\n/kaggle/input/2021-ml-p10/RawData/gyro_exp22_user11.txt\n/kaggle/input/2021-ml-p10/RawData/gyro_exp31_user15.txt\n/kaggle/input/2021-ml-p10/RawData/acc_exp19_user10.txt\n/kaggle/input/2021-ml-p10/RawData/acc_exp03_user02.txt\n/kaggle/input/2021-ml-p10/RawData/acc_exp04_user02.txt\n/kaggle/input/2021-ml-p10/RawData/acc_exp33_user16.txt\n/kaggle/input/2021-ml-p10/RawData/acc_exp07_user04.txt\n/kaggle/input/2021-ml-p10/RawData/acc_exp53_user26.txt\n/kaggle/input/2021-ml-p10/RawData/acc_exp22_user11.txt\n/kaggle/input/2021-ml-p10/RawData/acc_exp16_user08.txt\n/kaggle/input/2021-ml-p10/RawData/gyro_exp14_user07.txt\n/kaggle/input/2021-ml-p10/RawData/gyro_exp07_user04.txt\n/kaggle/input/2021-ml-p10/RawData/acc_exp57_user28.txt\n/kaggle/input/2021-ml-p10/RawData/gyro_exp09_user05.txt\n/kaggle/input/2021-ml-p10/RawData/gyro_exp48_user24.txt\n/kaggle/input/2021-ml-p10/RawData/gyro_exp56_user28.txt\n/kaggle/input/2021-ml-p10/RawData/gyro_exp35_user17.txt\n/kaggle/input/2021-ml-p10/RawData/gyro_exp02_user01.txt\n/kaggle/input/2021-ml-p10/RawData/acc_exp20_user10.txt\n/kaggle/input/2021-ml-p10/RawData/gyro_exp03_user02.txt\n/kaggle/input/2021-ml-p10/RawData/gyro_exp61_user30.txt\n/kaggle/input/2021-ml-p10/RawData/acc_exp51_user25.txt\n/kaggle/input/2021-ml-p10/RawData/gyro_exp37_user18.txt\n/kaggle/input/2021-ml-p10/RawData/acc_exp36_user18.txt\n/kaggle/input/2021-ml-p10/RawData/gyro_exp34_user17.txt\n/kaggle/input/2021-ml-p10/RawData/acc_exp48_user24.txt\n/kaggle/input/2021-ml-p10/RawData/acc_exp10_user05.txt\n/kaggle/input/2021-ml-p10/RawData/gyro_exp08_user04.txt\n/kaggle/input/2021-ml-p10/RawData/acc_exp56_user28.txt\n/kaggle/input/2021-ml-p10/RawData/gyro_exp41_user20.txt\n/kaggle/input/2021-ml-p10/RawData/acc_exp31_user15.txt\n/kaggle/input/2021-ml-p10/RawData/gyro_exp16_user08.txt\n/kaggle/input/2021-ml-p10/RawData/gyro_exp57_user28.txt\n/kaggle/input/2021-ml-p10/RawData/acc_exp42_user21.txt\n/kaggle/input/2021-ml-p10/RawData/acc_exp54_user27.txt\n/kaggle/input/2021-ml-p10/RawData/acc_exp34_user17.txt\n/kaggle/input/2021-ml-p10/RawData/gyro_exp55_user27.txt\n/kaggle/input/2021-ml-p10/RawData/gyro_exp04_user02.txt\n/kaggle/input/2021-ml-p10/RawData/acc_exp30_user15.txt\n/kaggle/input/2021-ml-p10/RawData/gyro_exp43_user21.txt\n/kaggle/input/2021-ml-p10/RawData/acc_exp29_user14.txt\n/kaggle/input/2021-ml-p10/RawData/gyro_exp47_user23.txt\n/kaggle/input/2021-ml-p10/RawData/gyro_exp58_user29.txt\n/kaggle/input/2021-ml-p10/RawData/gyro_exp39_user19.txt\n/kaggle/input/2021-ml-p10/RawData/gyro_exp21_user10.txt\n/kaggle/input/2021-ml-p10/RawData/acc_exp14_user07.txt\n/kaggle/input/2021-ml-p10/RawData/acc_exp17_user09.txt\n/kaggle/input/2021-ml-p10/RawData/acc_exp02_user01.txt\n/kaggle/input/2021-ml-p10/RawData/gyro_exp33_user16.txt\n/kaggle/input/2021-ml-p10/RawData/gyro_exp30_user15.txt\n/kaggle/input/2021-ml-p10/RawData/gyro_exp24_user12.txt\n/kaggle/input/2021-ml-p10/RawData/gyro_exp15_user08.txt\n/kaggle/input/2021-ml-p10/RawData/acc_exp38_user19.txt\n/kaggle/input/2021-ml-p10/RawData/acc_exp25_user12.txt\n/kaggle/input/2021-ml-p10/RawData/gyro_exp10_user05.txt\n/kaggle/input/2021-ml-p10/RawData/acc_exp47_user23.txt\n/kaggle/input/2021-ml-p10/RawData/acc_exp58_user29.txt\n","output_type":"stream"}]},{"cell_type":"code","source":"# Importing numpy \nimport numpy as np\n# Importing Scipy \nimport scipy as sp\n# Importing Pandas Library \nimport pandas as pd\n# import glob function to scrap files path\nfrom glob import glob\n# import display() for better visualitions of DataFrames and arrays\nfrom IPython.display import display\n# import pyplot for plotting\nimport matplotlib.pyplot as plt\nplt.style.use('bmh') # for better plots\nimport tqdm\n\n# import data_loader for data loading\nfrom data_loader import import_raw_signals, import_labels_file,normalize5,normalize2","metadata":{"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Raw 데이터 불러오기\n\n### Data Tree\n\n```\n+--RawData\n|  +--acc_exp01_user01.txt\n|  +--...(61개)\n|  +--gyro_exp01_user01.txt\n|  +--...(61개)\n|  +--label_train.txt\n|  +--label_test.txt\n\n```","metadata":{}},{"cell_type":"code","source":"Raw_data_paths = sorted(glob(\"/kaggle/input/2021-ml-p10/RawData/*\"))\nRaw_acc_paths=Raw_data_paths[0:61]\nRaw_gyro_paths=Raw_data_paths[61:122]\n\nprint ((\"RawData folder contains in total {:d} file \").format(len(Raw_data_paths)))\nprint ((\"The first {:d} are Acceleration files:\").format(len(Raw_acc_paths)))\nprint ((\"The second {:d} are Gyroscope files:\").format(len(Raw_gyro_paths)))\nprint (\"The last file is a labels file\")\nprint (\"test labels file path is:\",Raw_data_paths[122])\nprint (\"train labels file path is:\",Raw_data_paths[123])","metadata":{"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"RawData folder contains in total 124 file \nThe first 61 are Acceleration files:\nThe second 61 are Gyroscope files:\nThe last file is a labels file\ntest labels file path is: /kaggle/input/2021-ml-p10/RawData/label_test.txt\ntrain labels file path is: /kaggle/input/2021-ml-p10/RawData/label_train.txt\n","output_type":"stream"}]},{"cell_type":"code","source":"raw_dic={}\nraw_acc_columns=['acc_X','acc_Y','acc_Z']\nraw_gyro_columns=['gyro_X','gyro_Y','gyro_Z']\nfor path_index in range(0,61):\n        key= Raw_data_paths[path_index][-16:-4]\n        raw_acc_data_frame=import_raw_signals(Raw_data_paths[path_index],raw_acc_columns)\n        raw_gyro_data_frame=import_raw_signals(Raw_data_paths[path_index+61],raw_gyro_columns)\n        raw_signals_data_frame=pd.concat([raw_acc_data_frame, raw_gyro_data_frame], axis=1)\n        raw_dic[key]=raw_signals_data_frame","metadata":{"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"print('raw_dic contains %d DataFrame' % len(raw_dic))\ndisplay(raw_dic['exp01_user01'].head(3))","metadata":{"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"raw_dic contains 61 DataFrame\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"      acc_X     acc_Y     acc_Z    gyro_X    gyro_Y    gyro_Z\n0  0.918056 -0.112500  0.509722 -0.054978 -0.069639 -0.030849\n1  0.911111 -0.093056  0.537500 -0.012523  0.019242 -0.038485\n2  0.881944 -0.086111  0.513889 -0.023518  0.276417  0.006414","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>acc_X</th>\n      <th>acc_Y</th>\n      <th>acc_Z</th>\n      <th>gyro_X</th>\n      <th>gyro_Y</th>\n      <th>gyro_Z</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.918056</td>\n      <td>-0.112500</td>\n      <td>0.509722</td>\n      <td>-0.054978</td>\n      <td>-0.069639</td>\n      <td>-0.030849</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.911111</td>\n      <td>-0.093056</td>\n      <td>0.537500</td>\n      <td>-0.012523</td>\n      <td>0.019242</td>\n      <td>-0.038485</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.881944</td>\n      <td>-0.086111</td>\n      <td>0.513889</td>\n      <td>-0.023518</td>\n      <td>0.276417</td>\n      <td>0.006414</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Label 불러오기\n\nLabel 정보\n```\ntrain\nexperiment_number_ID : 실험 ID\nuser_number_ID : 유저 ID\nactivity_number_ID : 활동 ID\nLabel_start_point : Raw 데이터에서 행동이 시작하는 지점(시간)\nLabel_end_point : RAW 데이터에서 행동이 끝나는 지점(시간)\n\ntest\nexperiment_number_ID : 실험 ID\nuser_number_ID : 유저 ID\nLabel_start_point : Raw 데이터에서 행동이 시작하는 지점(시간)\nLabel_end_point : RAW 데이터에서 행동이 끝나는 지점(시간)\n```","metadata":{}},{"cell_type":"code","source":"train_raw_labels_columns=['experiment_number_ID','user_number_ID','activity_number_ID','Label_start_point','Label_end_point']\ntest_raw_labels_columns=['experiment_number_ID','user_number_ID','Label_start_point','Label_end_point']\n\ntest_labels_path=Raw_data_paths[122]\ntrain_labels_path=Raw_data_paths[123]\n\ntrain_Labels_Data_Frame=import_labels_file(train_labels_path,train_raw_labels_columns)\ntest_Labels_Data_Frame=import_labels_file(test_labels_path,test_raw_labels_columns)","metadata":{"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"print (\"The first 3 rows of  train_Labels_Data_Frame:\" )\ndisplay(train_Labels_Data_Frame.head(3))\nprint(train_Labels_Data_Frame.shape)\ndisplay(test_Labels_Data_Frame.head(3))\nprint(test_Labels_Data_Frame.shape)","metadata":{"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"The first 3 rows of  train_Labels_Data_Frame:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"   experiment_number_ID  user_number_ID  activity_number_ID  \\\n0                     1               1                   5   \n1                     1               1                   4   \n2                     1               1                   5   \n\n   Label_start_point  Label_end_point  \n0                250             1232  \n1               1393             2194  \n2               2360             3374  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>experiment_number_ID</th>\n      <th>user_number_ID</th>\n      <th>activity_number_ID</th>\n      <th>Label_start_point</th>\n      <th>Label_end_point</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>5</td>\n      <td>250</td>\n      <td>1232</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1393</td>\n      <td>2194</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>1</td>\n      <td>5</td>\n      <td>2360</td>\n      <td>3374</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"(598, 5)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"   experiment_number_ID  user_number_ID  Label_start_point  Label_end_point\n0                     3               2                298             1398\n1                     3               2               1686             2627\n2                     3               2               2770             3904","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>experiment_number_ID</th>\n      <th>user_number_ID</th>\n      <th>Label_start_point</th>\n      <th>Label_end_point</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>2</td>\n      <td>298</td>\n      <td>1398</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>2</td>\n      <td>1686</td>\n      <td>2627</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>2</td>\n      <td>2770</td>\n      <td>3904</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"(258, 4)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 데이터 전처리","metadata":{}},{"cell_type":"markdown","source":"### Median Filter","metadata":{}},{"cell_type":"code","source":"from scipy.signal import medfilt\n\ndef median(signal):\n    array=np.array(signal)   \n    med_filtered=sp.signal.medfilt(array, kernel_size=3)\n    return  med_filtered","metadata":{"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### Butterworth Filter를 통한 성분분해","metadata":{}},{"cell_type":"code","source":"from scipy.fftpack import fft  \nfrom scipy.fftpack import fftfreq\nfrom scipy.fftpack import ifft\nimport math \n\nsampling_freq = 50\nnyq=sampling_freq/float(2)\nfreq1 = 0.3\nfreq2 = 20\n\n# Function name: components_selection_one_signal\n\n# Inputs: t_signal:1D numpy array (time domain signal); \n\n# Outputs: (total_component,t_DC_component , t_body_component, t_noise) \n#           type(1D array,1D array, 1D array)\n\n# cases to discuss: if the t_signal is an acceleration signal then the t_DC_component is the gravity component [Grav_acc]\n#                   if the t_signal is a gyro signal then the t_DC_component is not useful\n# t_noise component is not useful\n# if the t_signal is an acceleration signal then the t_body_component is the body's acceleration component [Body_acc]\n# if the t_signal is a gyro signal then the t_body_component is the body's angular velocity component [Body_gyro]\n\ndef components_selection_one_signal(t_signal,freq1,freq2):\n    t_signal=np.array(t_signal)\n    t_signal_length=len(t_signal)\n    f_signal=fft(t_signal)\n    freqs=np.array(sp.fftpack.fftfreq(t_signal_length, d=1/float(sampling_freq)))# frequency values between [-25hz:+25hz]\n    \n    # DC_component: f_signal values having freq between [-0.3 hz to 0 hz] and from [0 hz to 0.3hz] \n    #                                                             (-0.3 and 0.3 are included)\n    \n    # noise components: f_signal values having freq between [-25 hz to 20 hz[ and from ] 20 hz to 25 hz] \n    #                                                               (-25 and 25 hz inculded 20hz and -20hz not included)\n    \n    # selecting body_component: f_signal values having freq between [-20 hz to -0.3 hz] and from [0.3 hz to 20 hz] \n    #                                                               (-0.3 and 0.3 not included , -20hz and 20 hz included)\n    \n    \n    f_DC_signal=[] # DC_component in freq domain\n    f_body_signal=[] # body component in freq domain numpy.append(a, a[0])\n    f_noise_signal=[] # noise in freq domain\n    \n    for i in range(len(freqs)):# iterate over all available frequencies\n        \n        # selecting the frequency value\n        freq=freqs[i]\n        \n        # selecting the f_signal value associated to freq\n        value= f_signal[i]\n        \n        # Selecting DC_component values \n        if abs(freq)>0.3:# testing if freq is outside DC_component frequency ranges\n            f_DC_signal.append(float(0)) # add 0 to  the  list if it was the case (the value should not be added)                                       \n        else: # if freq is inside DC_component frequency ranges \n            f_DC_signal.append(value) # add f_signal value to f_DC_signal list\n    \n        # Selecting noise component values \n        if (abs(freq)<=20):# testing if freq is outside noise frequency ranges \n            f_noise_signal.append(float(0)) # # add 0 to  f_noise_signal list if it was the case \n        else:# if freq is inside noise frequency ranges \n            f_noise_signal.append(value) # add f_signal value to f_noise_signal\n\n        # Selecting body_component values \n        if (abs(freq)<=0.3 or abs(freq)>20):# testing if freq is outside Body_component frequency ranges\n            f_body_signal.append(float(0))# add 0 to  f_body_signal list\n        else:# if freq is inside Body_component frequency ranges\n            f_body_signal.append(value) # add f_signal value to f_body_signal list\n    \n    ################### Inverse the transformation of signals in freq domain ########################\n    # applying the inverse fft(ifft) to signals in freq domain and put them in float format\n    t_DC_component= ifft(np.array(f_DC_signal)).real\n    t_body_component= ifft(np.array(f_body_signal)).real\n    t_noise=ifft(np.array(f_noise_signal)).real\n    \n    total_component=t_signal-t_noise # extracting the total component(filtered from noise) \n                                     #  by substracting noise from t_signal (the original signal).\n    \n    # return outputs mentioned earlier\n    return (total_component,t_DC_component,t_body_component,t_noise) ","metadata":{"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## 피처모델링\n","metadata":{}},{"cell_type":"markdown","source":"### 1. 유클리드 Norm을 통한 가속도,자이로 센서 크기(Magnitude) 계산","metadata":{}},{"cell_type":"code","source":"import math\ndef mag_3_signals(x,y,z): # Euclidian magnitude\n    return [math.sqrt((x[i]**2+y[i]**2+z[i]**2)) for i in range(len(x))]","metadata":{"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"### 2. 미분을 통한 변화량(Jerk) 계산","metadata":{}},{"cell_type":"code","source":"dt=0.02 # dt=1/50=0.02s time duration between two rows\n# Input: 1D array with lenght=N (N:unknown)\n# Output: 1D array with lenght=N-1\ndef jerk_one_signal(signal): \n        return np.array([(signal[i+1]-signal[i])/dt for i in range(len(signal)-1)])","metadata":{"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"time_sig_dic={}\nraw_dic_keys=sorted(raw_dic.keys())\n\nfor key in tqdm.tqdm(raw_dic_keys):\n    raw_df=raw_dic[key]\n    time_sig_df=pd.DataFrame()\n    \n    for column in raw_df.columns:\n        t_signal=np.array(raw_df[column])\n        med_filtred=median(t_signal)\n        \n        if 'acc' in column:\n            _,grav_acc,body_acc,_=components_selection_one_signal(med_filtred,freq1,freq2)\n            body_acc_jerk=jerk_one_signal(body_acc)\n            time_sig_df['t_body_'+column]=body_acc[:-1]\n            time_sig_df['t_grav_'+column]= grav_acc[:-1]\n            time_sig_df['t_body_acc_jerk_'+column[-1]]=body_acc_jerk\n        elif 'gyro' in column:\n            _,_,body_gyro,_=components_selection_one_signal(med_filtred,freq1,freq2)\n            body_gyro_jerk=jerk_one_signal(body_gyro)\n            time_sig_df['t_body_gyro_'+column[-1]]=body_gyro[:-1]\n            time_sig_df['t_body_gyro_jerk_'+column[-1]]=body_gyro_jerk\n            \n    new_columns_ordered=['t_body_acc_X','t_body_acc_Y','t_body_acc_Z',\n                      't_grav_acc_X','t_grav_acc_Y','t_grav_acc_Z',\n                      't_body_acc_jerk_X','t_body_acc_jerk_Y','t_body_acc_jerk_Z',\n                      't_body_gyro_X','t_body_gyro_Y','t_body_gyro_Z',\n                      't_body_gyro_jerk_X','t_body_gyro_jerk_Y','t_body_gyro_jerk_Z']\n        \n    ordered_time_sig_df=pd.DataFrame()\n        \n    for col in new_columns_ordered:\n        ordered_time_sig_df[col]=time_sig_df[col]\n        \n    for i in range(0,15,3):\n        mag_col_name=new_columns_ordered[i][:-1]+'mag'\n        col0=np.array(ordered_time_sig_df[new_columns_ordered[i]]) # copy X_component\n        col1=ordered_time_sig_df[new_columns_ordered[i+1]] # copy Y_component\n        col2=ordered_time_sig_df[new_columns_ordered[i+2]] # copy Z_component\n        mag_signal=mag_3_signals(col0,col1,col2)\n        ordered_time_sig_df[mag_col_name]=mag_signal\n        \n    time_sig_dic[key]=ordered_time_sig_df","metadata":{"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"100%|██████████| 61/61 [01:58<00:00,  1.94s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"display(time_sig_dic['exp01_user01'].shape)\ndisplay(time_sig_dic['exp01_user01'].describe())\ntime_sig_dic['exp01_user01'].head(3)","metadata":{"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"(20597, 20)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"       t_body_acc_X  t_body_acc_Y  t_body_acc_Z  t_grav_acc_X  t_grav_acc_Y  \\\ncount  20597.000000  20597.000000  20597.000000  20597.000000  20597.000000   \nmean       0.000018     -0.000014     -0.000009      0.880358     -0.101501   \nstd        0.167505      0.123847      0.106477      0.299187      0.314444   \nmin       -0.698870     -0.993486     -0.671478     -0.231975     -0.367943   \n25%       -0.044563     -0.024197     -0.042269      0.968003     -0.275034   \n50%       -0.001207      0.002857     -0.003154      0.997735     -0.236751   \n75%        0.020914      0.051177      0.026000      1.007358     -0.123642   \nmax        1.031485      0.473201      0.493350      1.066684      0.832075   \n\n       t_grav_acc_Z  t_body_acc_jerk_X  t_body_acc_jerk_Y  t_body_acc_jerk_Z  \\\ncount  20597.000000       20597.000000       20597.000000       20597.000000   \nmean       0.097309          -0.001833           0.001183           0.000849   \nstd        0.262835           4.076298           3.237138           2.298076   \nmin       -0.161622         -38.735217         -33.718078         -24.262993   \n25%       -0.050273          -0.481136          -0.422376          -0.347403   \n50%       -0.025435           0.003867           0.003613           0.003452   \n75%        0.090625           0.568717           0.505230           0.381417   \nmax        1.015052          34.647970          34.482683          35.302951   \n\n       t_body_gyro_X  t_body_gyro_Y  t_body_gyro_Z  t_body_gyro_jerk_X  \\\ncount   2.059700e+04   20597.000000   20597.000000        20597.000000   \nmean    3.259619e-07       0.000008       0.000010            0.000046   \nstd     3.907032e-01       0.497555       0.265791            7.641439   \nmin    -3.141414e+00      -2.694787      -4.050512          -90.662943   \n25%    -1.189116e-01      -0.139441      -0.059319           -1.100310   \n50%     3.737832e-03      -0.002389       0.003384            0.003147   \n75%     1.546320e-01       0.101817       0.088021            1.159630   \nmax     2.698454e+00       4.530312       2.260099           95.696959   \n\n       t_body_gyro_jerk_Y  t_body_gyro_jerk_Z  t_body_acc_mag  t_grav_acc_mag  \\\ncount        20597.000000        20597.000000    20597.000000    20597.000000   \nmean             0.000095            0.000362        0.165296        1.025479   \nstd             13.033311            5.724163        0.165557        0.025535   \nmin           -158.457438          -89.662267        0.000864        0.768925   \n25%             -1.705868           -0.832493        0.025437        1.021875   \n50%             -0.005965           -0.002999        0.114319        1.031724   \n75%              1.392834            0.799237        0.262351        1.038524   \nmax            151.910819           60.809206        1.180706        1.115731   \n\n       t_body_acc_jerk_mag  t_body_gyro_mag  t_body_gyro_jerk_mag  \ncount         20597.000000     20597.000000          20597.000000  \nmean              3.404274         0.489705              9.439402  \nstd               4.559251         0.480657             13.111758  \nmin               0.006144         0.001641              0.017986  \n25%               0.272200         0.087023              0.506674  \n50%               1.581932         0.348679              4.510858  \n75%               4.837894         0.758609             13.308692  \nmax              54.209353         6.249451            160.671661  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>t_body_acc_X</th>\n      <th>t_body_acc_Y</th>\n      <th>t_body_acc_Z</th>\n      <th>t_grav_acc_X</th>\n      <th>t_grav_acc_Y</th>\n      <th>t_grav_acc_Z</th>\n      <th>t_body_acc_jerk_X</th>\n      <th>t_body_acc_jerk_Y</th>\n      <th>t_body_acc_jerk_Z</th>\n      <th>t_body_gyro_X</th>\n      <th>t_body_gyro_Y</th>\n      <th>t_body_gyro_Z</th>\n      <th>t_body_gyro_jerk_X</th>\n      <th>t_body_gyro_jerk_Y</th>\n      <th>t_body_gyro_jerk_Z</th>\n      <th>t_body_acc_mag</th>\n      <th>t_grav_acc_mag</th>\n      <th>t_body_acc_jerk_mag</th>\n      <th>t_body_gyro_mag</th>\n      <th>t_body_gyro_jerk_mag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>20597.000000</td>\n      <td>20597.000000</td>\n      <td>20597.000000</td>\n      <td>20597.000000</td>\n      <td>20597.000000</td>\n      <td>20597.000000</td>\n      <td>20597.000000</td>\n      <td>20597.000000</td>\n      <td>20597.000000</td>\n      <td>2.059700e+04</td>\n      <td>20597.000000</td>\n      <td>20597.000000</td>\n      <td>20597.000000</td>\n      <td>20597.000000</td>\n      <td>20597.000000</td>\n      <td>20597.000000</td>\n      <td>20597.000000</td>\n      <td>20597.000000</td>\n      <td>20597.000000</td>\n      <td>20597.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.000018</td>\n      <td>-0.000014</td>\n      <td>-0.000009</td>\n      <td>0.880358</td>\n      <td>-0.101501</td>\n      <td>0.097309</td>\n      <td>-0.001833</td>\n      <td>0.001183</td>\n      <td>0.000849</td>\n      <td>3.259619e-07</td>\n      <td>0.000008</td>\n      <td>0.000010</td>\n      <td>0.000046</td>\n      <td>0.000095</td>\n      <td>0.000362</td>\n      <td>0.165296</td>\n      <td>1.025479</td>\n      <td>3.404274</td>\n      <td>0.489705</td>\n      <td>9.439402</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.167505</td>\n      <td>0.123847</td>\n      <td>0.106477</td>\n      <td>0.299187</td>\n      <td>0.314444</td>\n      <td>0.262835</td>\n      <td>4.076298</td>\n      <td>3.237138</td>\n      <td>2.298076</td>\n      <td>3.907032e-01</td>\n      <td>0.497555</td>\n      <td>0.265791</td>\n      <td>7.641439</td>\n      <td>13.033311</td>\n      <td>5.724163</td>\n      <td>0.165557</td>\n      <td>0.025535</td>\n      <td>4.559251</td>\n      <td>0.480657</td>\n      <td>13.111758</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-0.698870</td>\n      <td>-0.993486</td>\n      <td>-0.671478</td>\n      <td>-0.231975</td>\n      <td>-0.367943</td>\n      <td>-0.161622</td>\n      <td>-38.735217</td>\n      <td>-33.718078</td>\n      <td>-24.262993</td>\n      <td>-3.141414e+00</td>\n      <td>-2.694787</td>\n      <td>-4.050512</td>\n      <td>-90.662943</td>\n      <td>-158.457438</td>\n      <td>-89.662267</td>\n      <td>0.000864</td>\n      <td>0.768925</td>\n      <td>0.006144</td>\n      <td>0.001641</td>\n      <td>0.017986</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>-0.044563</td>\n      <td>-0.024197</td>\n      <td>-0.042269</td>\n      <td>0.968003</td>\n      <td>-0.275034</td>\n      <td>-0.050273</td>\n      <td>-0.481136</td>\n      <td>-0.422376</td>\n      <td>-0.347403</td>\n      <td>-1.189116e-01</td>\n      <td>-0.139441</td>\n      <td>-0.059319</td>\n      <td>-1.100310</td>\n      <td>-1.705868</td>\n      <td>-0.832493</td>\n      <td>0.025437</td>\n      <td>1.021875</td>\n      <td>0.272200</td>\n      <td>0.087023</td>\n      <td>0.506674</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>-0.001207</td>\n      <td>0.002857</td>\n      <td>-0.003154</td>\n      <td>0.997735</td>\n      <td>-0.236751</td>\n      <td>-0.025435</td>\n      <td>0.003867</td>\n      <td>0.003613</td>\n      <td>0.003452</td>\n      <td>3.737832e-03</td>\n      <td>-0.002389</td>\n      <td>0.003384</td>\n      <td>0.003147</td>\n      <td>-0.005965</td>\n      <td>-0.002999</td>\n      <td>0.114319</td>\n      <td>1.031724</td>\n      <td>1.581932</td>\n      <td>0.348679</td>\n      <td>4.510858</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.020914</td>\n      <td>0.051177</td>\n      <td>0.026000</td>\n      <td>1.007358</td>\n      <td>-0.123642</td>\n      <td>0.090625</td>\n      <td>0.568717</td>\n      <td>0.505230</td>\n      <td>0.381417</td>\n      <td>1.546320e-01</td>\n      <td>0.101817</td>\n      <td>0.088021</td>\n      <td>1.159630</td>\n      <td>1.392834</td>\n      <td>0.799237</td>\n      <td>0.262351</td>\n      <td>1.038524</td>\n      <td>4.837894</td>\n      <td>0.758609</td>\n      <td>13.308692</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.031485</td>\n      <td>0.473201</td>\n      <td>0.493350</td>\n      <td>1.066684</td>\n      <td>0.832075</td>\n      <td>1.015052</td>\n      <td>34.647970</td>\n      <td>34.482683</td>\n      <td>35.302951</td>\n      <td>2.698454e+00</td>\n      <td>4.530312</td>\n      <td>2.260099</td>\n      <td>95.696959</td>\n      <td>151.910819</td>\n      <td>60.809206</td>\n      <td>1.180706</td>\n      <td>1.115731</td>\n      <td>54.209353</td>\n      <td>6.249451</td>\n      <td>160.671661</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"   t_body_acc_X  t_body_acc_Y  t_body_acc_Z  t_grav_acc_X  t_grav_acc_Y  \\\n0      0.382899     -0.206562     -0.169117      0.431759      0.175976   \n1      0.550980     -0.317339     -0.239649      0.443087      0.169277   \n2      0.368165     -0.207616     -0.165561      0.454376      0.162556   \n\n   t_grav_acc_Z  t_body_acc_jerk_X  t_body_acc_jerk_Y  t_body_acc_jerk_Z  \\\n0      0.720859           8.404087          -5.538872          -3.526643   \n1      0.715098          -9.140781           5.486163           3.704421   \n2      0.709293           3.968636          -2.902182          -2.103241   \n\n   t_body_gyro_X  t_body_gyro_Y  t_body_gyro_Z  t_body_gyro_jerk_X  \\\n0      -0.025624      -0.210093      -0.361419            0.552413   \n1      -0.014575      -0.146141      -0.377275           -0.185277   \n2      -0.018281       0.079766      -0.329582           -2.485754   \n\n   t_body_gyro_jerk_Y  t_body_gyro_jerk_Z  t_body_acc_mag  t_grav_acc_mag  \\\n0            3.197618           -0.792801        0.466776        0.858500   \n1           11.295307            2.384643        0.679496        0.858106   \n2            6.100713           -0.485211        0.453938        0.857892   \n\n   t_body_acc_jerk_mag  t_body_gyro_mag  t_body_gyro_jerk_mag  \n0            10.665130         0.418831              3.340427  \n1            11.286035         0.404853             11.545770  \n2             5.347556         0.339590              6.605536  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>t_body_acc_X</th>\n      <th>t_body_acc_Y</th>\n      <th>t_body_acc_Z</th>\n      <th>t_grav_acc_X</th>\n      <th>t_grav_acc_Y</th>\n      <th>t_grav_acc_Z</th>\n      <th>t_body_acc_jerk_X</th>\n      <th>t_body_acc_jerk_Y</th>\n      <th>t_body_acc_jerk_Z</th>\n      <th>t_body_gyro_X</th>\n      <th>t_body_gyro_Y</th>\n      <th>t_body_gyro_Z</th>\n      <th>t_body_gyro_jerk_X</th>\n      <th>t_body_gyro_jerk_Y</th>\n      <th>t_body_gyro_jerk_Z</th>\n      <th>t_body_acc_mag</th>\n      <th>t_grav_acc_mag</th>\n      <th>t_body_acc_jerk_mag</th>\n      <th>t_body_gyro_mag</th>\n      <th>t_body_gyro_jerk_mag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.382899</td>\n      <td>-0.206562</td>\n      <td>-0.169117</td>\n      <td>0.431759</td>\n      <td>0.175976</td>\n      <td>0.720859</td>\n      <td>8.404087</td>\n      <td>-5.538872</td>\n      <td>-3.526643</td>\n      <td>-0.025624</td>\n      <td>-0.210093</td>\n      <td>-0.361419</td>\n      <td>0.552413</td>\n      <td>3.197618</td>\n      <td>-0.792801</td>\n      <td>0.466776</td>\n      <td>0.858500</td>\n      <td>10.665130</td>\n      <td>0.418831</td>\n      <td>3.340427</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.550980</td>\n      <td>-0.317339</td>\n      <td>-0.239649</td>\n      <td>0.443087</td>\n      <td>0.169277</td>\n      <td>0.715098</td>\n      <td>-9.140781</td>\n      <td>5.486163</td>\n      <td>3.704421</td>\n      <td>-0.014575</td>\n      <td>-0.146141</td>\n      <td>-0.377275</td>\n      <td>-0.185277</td>\n      <td>11.295307</td>\n      <td>2.384643</td>\n      <td>0.679496</td>\n      <td>0.858106</td>\n      <td>11.286035</td>\n      <td>0.404853</td>\n      <td>11.545770</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.368165</td>\n      <td>-0.207616</td>\n      <td>-0.165561</td>\n      <td>0.454376</td>\n      <td>0.162556</td>\n      <td>0.709293</td>\n      <td>3.968636</td>\n      <td>-2.902182</td>\n      <td>-2.103241</td>\n      <td>-0.018281</td>\n      <td>0.079766</td>\n      <td>-0.329582</td>\n      <td>-2.485754</td>\n      <td>6.100713</td>\n      <td>-0.485211</td>\n      <td>0.453938</td>\n      <td>0.857892</td>\n      <td>5.347556</td>\n      <td>0.339590</td>\n      <td>6.605536</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### 데이터 샘플링\n\n```\n2.56초를 기준으로 Raw 데이터 샘플링\n50%는 오버랩 하여 샘플링을 수행\n```","metadata":{}},{"cell_type":"code","source":"def Windowing_type(time_sig_dic,Labels_Data_Frame):\n    import pdb;pdb.set_trace()\n    columns=time_sig_dic['exp01_user01'].columns\n    window_ID=0\n    time_dictionary_window={}\n    BA_array=np.array(Labels_Data_Frame)\n    \n    for line in tqdm.tqdm(BA_array):\n        file_key= 'exp' + normalize2(int(line[0]))  +  '_user' + normalize2(int(line[1]))\n        \n        if line.shape[0] == 5 :\n          act_ID=line[2]\n          start_point=line[3]\n          end_point = line[4]\n        else :\n          act_ID='None'\n          start_point = line[2]\n          end_point = line[3]\n        \n        for cursor in range(start_point,end_point-127,64):\n            end_point=cursor+128\n            data=np.array(time_sig_dic[file_key].iloc[cursor:end_point])\n            window=pd.DataFrame(data=data,columns=columns)\n            key='t_W'+normalize5(window_ID)+'_'+file_key+'_act'+normalize2(act_ID)\n            time_dictionary_window[key]=window\n            window_ID=window_ID+1\n    \n    return time_dictionary_window ","metadata":{"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"train_time_dictionary_window  = Windowing_type(time_sig_dic,train_Labels_Data_Frame)\ntest_time_dictionary_window  = Windowing_type(time_sig_dic,test_Labels_Data_Frame)","metadata":{"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"> \u001b[0;32m<ipython-input-16-ede7e2832bd4>\u001b[0m(3)\u001b[0;36mWindowing_type\u001b[0;34m()\u001b[0m\n\u001b[0;32m      1 \u001b[0;31m\u001b[0;32mdef\u001b[0m \u001b[0mWindowing_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_sig_dic\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLabels_Data_Frame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2 \u001b[0;31m    \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m----> 3 \u001b[0;31m    \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_sig_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'exp01_user01'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4 \u001b[0;31m    \u001b[0mwindow_ID\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5 \u001b[0;31m    \u001b[0mtime_dictionary_window\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"ipdb>  continue\n"},{"name":"stderr","text":"100%|██████████| 598/598 [00:05<00:00, 109.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"> \u001b[0;32m<ipython-input-16-ede7e2832bd4>\u001b[0m(3)\u001b[0;36mWindowing_type\u001b[0;34m()\u001b[0m\n\u001b[0;32m      1 \u001b[0;31m\u001b[0;32mdef\u001b[0m \u001b[0mWindowing_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_sig_dic\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLabels_Data_Frame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2 \u001b[0;31m    \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m----> 3 \u001b[0;31m    \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_sig_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'exp01_user01'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4 \u001b[0;31m    \u001b[0mwindow_ID\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5 \u001b[0;31m    \u001b[0mtime_dictionary_window\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"ipdb>  continue\n"},{"name":"stderr","text":"100%|██████████| 258/258 [00:02<00:00, 114.48it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"train_window = train_time_dictionary_window[sorted(train_time_dictionary_window.keys())[0]]\ntrain_window.head()","metadata":{"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"   t_body_acc_X  t_body_acc_Y  t_body_acc_Z  t_grav_acc_X  t_grav_acc_Y  \\\n0     -0.003068      0.009275     -0.049713      1.025297     -0.135052   \n1     -0.004362      0.010634     -0.049921      1.025123     -0.135542   \n2     -0.005253      0.011620     -0.046143      1.024940     -0.136014   \n3     -0.004821      0.010402     -0.045727      1.024747     -0.136467   \n4     -0.008388      0.010250     -0.041144      1.024545     -0.136900   \n\n   t_grav_acc_Z  t_body_acc_jerk_X  t_body_acc_jerk_Y  t_body_acc_jerk_Z  \\\n0      0.153468          -0.064668           0.067917          -0.010441   \n1      0.152980          -0.044544           0.049300           0.188938   \n2      0.152417           0.021576          -0.060893           0.020793   \n3      0.151784          -0.178322          -0.007597           0.229162   \n4      0.151080           0.168810          -0.075081          -0.268611   \n\n   t_body_gyro_X  t_body_gyro_Y  t_body_gyro_Z  t_body_gyro_jerk_X  \\\n0       0.023431       0.089860       0.049693           -0.193282   \n1       0.019565       0.079820       0.053780            0.630392   \n2       0.032173       0.099660       0.046247           -0.058003   \n3       0.031013       0.098705       0.041935           -0.260247   \n4       0.025808       0.098479       0.051237            0.188867   \n\n   t_body_gyro_jerk_Y  t_body_gyro_jerk_Z  t_body_acc_mag  t_grav_acc_mag  \\\n0           -0.501977            0.204316        0.050664        1.045479   \n1            0.991992           -0.376632        0.051227        1.045300   \n2           -0.047758           -0.215589        0.047872        1.045099   \n3           -0.011292            0.465103        0.047142        1.044877   \n4            0.892604           -0.057455        0.043223        1.044634   \n\n   t_body_acc_jerk_mag  t_body_gyro_mag  t_body_gyro_jerk_mag  \n0             0.094359         0.105324              0.575399  \n1             0.200280         0.098216              1.234218  \n2             0.067866         0.114481              0.228307  \n3             0.290469         0.111638              0.533083  \n4             0.326015         0.113971              0.914174  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>t_body_acc_X</th>\n      <th>t_body_acc_Y</th>\n      <th>t_body_acc_Z</th>\n      <th>t_grav_acc_X</th>\n      <th>t_grav_acc_Y</th>\n      <th>t_grav_acc_Z</th>\n      <th>t_body_acc_jerk_X</th>\n      <th>t_body_acc_jerk_Y</th>\n      <th>t_body_acc_jerk_Z</th>\n      <th>t_body_gyro_X</th>\n      <th>t_body_gyro_Y</th>\n      <th>t_body_gyro_Z</th>\n      <th>t_body_gyro_jerk_X</th>\n      <th>t_body_gyro_jerk_Y</th>\n      <th>t_body_gyro_jerk_Z</th>\n      <th>t_body_acc_mag</th>\n      <th>t_grav_acc_mag</th>\n      <th>t_body_acc_jerk_mag</th>\n      <th>t_body_gyro_mag</th>\n      <th>t_body_gyro_jerk_mag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.003068</td>\n      <td>0.009275</td>\n      <td>-0.049713</td>\n      <td>1.025297</td>\n      <td>-0.135052</td>\n      <td>0.153468</td>\n      <td>-0.064668</td>\n      <td>0.067917</td>\n      <td>-0.010441</td>\n      <td>0.023431</td>\n      <td>0.089860</td>\n      <td>0.049693</td>\n      <td>-0.193282</td>\n      <td>-0.501977</td>\n      <td>0.204316</td>\n      <td>0.050664</td>\n      <td>1.045479</td>\n      <td>0.094359</td>\n      <td>0.105324</td>\n      <td>0.575399</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.004362</td>\n      <td>0.010634</td>\n      <td>-0.049921</td>\n      <td>1.025123</td>\n      <td>-0.135542</td>\n      <td>0.152980</td>\n      <td>-0.044544</td>\n      <td>0.049300</td>\n      <td>0.188938</td>\n      <td>0.019565</td>\n      <td>0.079820</td>\n      <td>0.053780</td>\n      <td>0.630392</td>\n      <td>0.991992</td>\n      <td>-0.376632</td>\n      <td>0.051227</td>\n      <td>1.045300</td>\n      <td>0.200280</td>\n      <td>0.098216</td>\n      <td>1.234218</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.005253</td>\n      <td>0.011620</td>\n      <td>-0.046143</td>\n      <td>1.024940</td>\n      <td>-0.136014</td>\n      <td>0.152417</td>\n      <td>0.021576</td>\n      <td>-0.060893</td>\n      <td>0.020793</td>\n      <td>0.032173</td>\n      <td>0.099660</td>\n      <td>0.046247</td>\n      <td>-0.058003</td>\n      <td>-0.047758</td>\n      <td>-0.215589</td>\n      <td>0.047872</td>\n      <td>1.045099</td>\n      <td>0.067866</td>\n      <td>0.114481</td>\n      <td>0.228307</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.004821</td>\n      <td>0.010402</td>\n      <td>-0.045727</td>\n      <td>1.024747</td>\n      <td>-0.136467</td>\n      <td>0.151784</td>\n      <td>-0.178322</td>\n      <td>-0.007597</td>\n      <td>0.229162</td>\n      <td>0.031013</td>\n      <td>0.098705</td>\n      <td>0.041935</td>\n      <td>-0.260247</td>\n      <td>-0.011292</td>\n      <td>0.465103</td>\n      <td>0.047142</td>\n      <td>1.044877</td>\n      <td>0.290469</td>\n      <td>0.111638</td>\n      <td>0.533083</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.008388</td>\n      <td>0.010250</td>\n      <td>-0.041144</td>\n      <td>1.024545</td>\n      <td>-0.136900</td>\n      <td>0.151080</td>\n      <td>0.168810</td>\n      <td>-0.075081</td>\n      <td>-0.268611</td>\n      <td>0.025808</td>\n      <td>0.098479</td>\n      <td>0.051237</td>\n      <td>0.188867</td>\n      <td>0.892604</td>\n      <td>-0.057455</td>\n      <td>0.043223</td>\n      <td>1.044634</td>\n      <td>0.326015</td>\n      <td>0.113971</td>\n      <td>0.914174</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print(\"시간 도메인 Train 데이터 수 : {}\".format(len(train_time_dictionary_window)))\nprint(\"시간 도메인 Test 데이터 수 : {}\".format(len(test_time_dictionary_window)))\nprint(\"윈도우 크기(2.56s => 128개) : {}\".format(len(train_window)))","metadata":{"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"시간 도메인 Train 데이터 수 : 7283\n시간 도메인 Test 데이터 수 : 3116\n윈도우 크기(2.56s => 128개) : 128\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### 3.FFT(Fast Fourier Transform)을 통한 시간 도메인-> 주파수 도메인 변환","metadata":{}},{"cell_type":"code","source":"from scipy import fftpack\nfrom numpy.fft import *\n\ndef fast_fourier_transform_one_signal(t_signal):\n    complex_f_signal= fftpack.fft(t_signal)\n    amplitude_f_signal=np.abs(complex_f_signal)\n    \n    return amplitude_f_signal\n\ndef fast_fourier_transform(t_window):\n    f_window=pd.DataFrame()\n    for column in t_window.columns:\n        if 'grav' not in column:\n            t_signal=np.array(t_window[column])\n            f_signal= np.apply_along_axis(fast_fourier_transform_one_signal,0,t_signal)\n            f_window[\"f_\"+column[2:]]=f_signal\n    return f_window","metadata":{"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"train_frequent_dictionary_window = {'f'+key[1:] : train_t_df.pipe(fast_fourier_transform) for key, train_t_df in tqdm.tqdm(train_time_dictionary_window.items())}\ntest_frequent_dictionary_window = {'f'+key[1:] : test_t_df.pipe(fast_fourier_transform) for key, test_t_df in tqdm.tqdm(test_time_dictionary_window.items())}","metadata":{"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"100%|██████████| 7283/7283 [01:16<00:00, 95.19it/s] \n100%|██████████| 3116/3116 [00:32<00:00, 94.49it/s] \n","output_type":"stream"}]},{"cell_type":"code","source":"train_window = train_frequent_dictionary_window[sorted(train_frequent_dictionary_window.keys())[0]]\ntrain_window.head()","metadata":{"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"   f_body_acc_X  f_body_acc_Y  f_body_acc_Z  f_body_acc_jerk_X  \\\n0      0.257558      0.055128      0.568459           0.004474   \n1      0.324072      1.169116      2.325911           0.794786   \n2      0.045438      0.300832      0.599853           0.220647   \n3      0.026573      0.162318      0.341578           0.195753   \n4      0.040355      0.192653      0.218084           0.391329   \n\n   f_body_acc_jerk_Y  f_body_acc_jerk_Z  f_body_gyro_X  f_body_gyro_Y  \\\n0           1.018802           2.057622       1.302252       2.880254   \n1           1.852232           4.739415       2.270811       8.786654   \n2           0.463545           1.179457       0.332364       2.154464   \n3           0.523164           0.458591       0.396876       1.331866   \n4           0.872601           1.024741       0.484334       0.835291   \n\n   f_body_gyro_Z  f_body_gyro_jerk_X  f_body_gyro_jerk_Y  f_body_gyro_jerk_Z  \\\n0       0.066856            0.574643            8.573938            3.442790   \n1       3.040972            5.543606           13.054902            4.222888   \n2       0.845314            1.462829            2.404663            0.720631   \n3       0.486980            2.359180            1.583174            0.965404   \n4       0.432675            4.736053            0.525072            1.014540   \n\n   f_body_acc_mag  f_body_acc_jerk_mag  f_body_gyro_mag  f_body_gyro_jerk_mag  \n0        3.790846            25.481237        14.048363             73.764900  \n1        0.110791             1.628419         2.657498              6.699360  \n2        0.721155             0.921396         1.619180              3.680039  \n3        0.326605             1.490716         0.289519              2.877012  \n4        0.252132             0.395907         0.434509              0.690402  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>f_body_acc_X</th>\n      <th>f_body_acc_Y</th>\n      <th>f_body_acc_Z</th>\n      <th>f_body_acc_jerk_X</th>\n      <th>f_body_acc_jerk_Y</th>\n      <th>f_body_acc_jerk_Z</th>\n      <th>f_body_gyro_X</th>\n      <th>f_body_gyro_Y</th>\n      <th>f_body_gyro_Z</th>\n      <th>f_body_gyro_jerk_X</th>\n      <th>f_body_gyro_jerk_Y</th>\n      <th>f_body_gyro_jerk_Z</th>\n      <th>f_body_acc_mag</th>\n      <th>f_body_acc_jerk_mag</th>\n      <th>f_body_gyro_mag</th>\n      <th>f_body_gyro_jerk_mag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.257558</td>\n      <td>0.055128</td>\n      <td>0.568459</td>\n      <td>0.004474</td>\n      <td>1.018802</td>\n      <td>2.057622</td>\n      <td>1.302252</td>\n      <td>2.880254</td>\n      <td>0.066856</td>\n      <td>0.574643</td>\n      <td>8.573938</td>\n      <td>3.442790</td>\n      <td>3.790846</td>\n      <td>25.481237</td>\n      <td>14.048363</td>\n      <td>73.764900</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.324072</td>\n      <td>1.169116</td>\n      <td>2.325911</td>\n      <td>0.794786</td>\n      <td>1.852232</td>\n      <td>4.739415</td>\n      <td>2.270811</td>\n      <td>8.786654</td>\n      <td>3.040972</td>\n      <td>5.543606</td>\n      <td>13.054902</td>\n      <td>4.222888</td>\n      <td>0.110791</td>\n      <td>1.628419</td>\n      <td>2.657498</td>\n      <td>6.699360</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.045438</td>\n      <td>0.300832</td>\n      <td>0.599853</td>\n      <td>0.220647</td>\n      <td>0.463545</td>\n      <td>1.179457</td>\n      <td>0.332364</td>\n      <td>2.154464</td>\n      <td>0.845314</td>\n      <td>1.462829</td>\n      <td>2.404663</td>\n      <td>0.720631</td>\n      <td>0.721155</td>\n      <td>0.921396</td>\n      <td>1.619180</td>\n      <td>3.680039</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.026573</td>\n      <td>0.162318</td>\n      <td>0.341578</td>\n      <td>0.195753</td>\n      <td>0.523164</td>\n      <td>0.458591</td>\n      <td>0.396876</td>\n      <td>1.331866</td>\n      <td>0.486980</td>\n      <td>2.359180</td>\n      <td>1.583174</td>\n      <td>0.965404</td>\n      <td>0.326605</td>\n      <td>1.490716</td>\n      <td>0.289519</td>\n      <td>2.877012</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.040355</td>\n      <td>0.192653</td>\n      <td>0.218084</td>\n      <td>0.391329</td>\n      <td>0.872601</td>\n      <td>1.024741</td>\n      <td>0.484334</td>\n      <td>0.835291</td>\n      <td>0.432675</td>\n      <td>4.736053</td>\n      <td>0.525072</td>\n      <td>1.014540</td>\n      <td>0.252132</td>\n      <td>0.395907</td>\n      <td>0.434509</td>\n      <td>0.690402</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print(\"주파수 도메인 Train 데이터 수 : {}\".format(len(train_frequent_dictionary_window)))\nprint(\"주파수 도메인 Test 데이터 수 : {}\".format(len(test_frequent_dictionary_window)))\nprint(\"피처의 갯수 : {}\".format(len(train_window)))","metadata":{"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"주파수 도메인 Train 데이터 수 : 7283\n주파수 도메인 Test 데이터 수 : 3116\n피처의 갯수 : 128\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### 4. Feature Extract","metadata":{}},{"cell_type":"code","source":"# -------------------------------------\n# [Empty Module #1] Feature Engineering\n# -------------------------------------\n\n# -------------------------------------\n# Feature Engineering\n# -------------------------------------\n# 목적: 제공된 36개의 시퀀스 도메인 데이터를 기반으로 유의미한 피처를 추출한다.\n# 입력인자: 시간(time) 도메인 Feature 20개 , 주파수(frequency) 도메인 Feature 16개\n# 출력인자: 분류모델 학습을 위한 Feature\n# -------------------------------------\n\n# ------------------------------------------------------------\n# 구현 가이드라인 - 논문에서 제안하는 Feature Engineering 방법\n# ------------------------------------------------------------\n#\n# mean(): Mean value\n# std(): Standard deviation\n# mad(): Median absolute deviation \n# max(): Largest value in array\n# min(): Smallest value in array\n# sma(): Signal magnitude area\n# energy(): Energy measure. Sum of the squares divided by the number of values. \n# iqr(): Interquartile range \n# entropy(): Signal entropy\n# arCoeff(): Autorregresion coefficients with Burg order equal to 4\n# correlation(): correlation coefficient between two signals\n# maxInds(): index of the frequency component with largest magnitude\n# meanFreq(): Weighted average of the frequency components to obtain a mean frequency\n# skewness(): skewness of the frequency domain signal \n# kurtosis(): kurtosis of the frequency domain signal \n# bandsEnergy(): Energy of a frequency interval within the 64 bins of the FFT of each window.\n# angle(): Angle between to vectors.\n\nimport sys\n\n# Time domain Feature Extract function\n\nfrom Feature_engineering import mean_axial,std_axial,mad_axial,max_axial,min_axial, t_sma_axial, t_energy_axial,IQR_axial,entropy_axial, t_arburg_axial, t_corr_axial\nfrom Feature_engineering import mean_mag,std_mag,mad_mag,max_mag,min_mag,t_sma_mag,t_energy_mag,IQR_mag,entropy_mag,t_arburg_mag\n\n# Frequency domain Feature Extract function\nfrom Feature_engineering import f_sma_axial,f_energy_axial,f_max_Inds_axial,f_mean_Freq_axial,f_skewness_and_kurtosis_axial,f_all_bands_energy_axial\nfrom Feature_engineering import f_sma_mag,f_energy_mag,f_max_Inds_mag,f_mean_Freq_mag,f_skewness_mag,f_kurtosis_mag\n\n# Additional Feature Extract function\nfrom Feature_engineering import angle_features\n\ndef feature_extractor(time_dictionary,freq_dictionary, condition='train') :\n    \n    \n    if condition is 'train' :\n        total_data = []\n        total_label = []\n    elif condition is 'test' :\n        total_data = []\n        \n    for i in tqdm.tqdm(range(len(time_dictionary))) :\n        \n        time_key = sorted(time_dictionary.keys())[i]\n        freq_key = sorted(freq_dictionary.keys())[i]\n        \n        time_window = time_dictionary[time_key]\n        freq_window = freq_dictionary[freq_key]\n        \n        if condition is 'train' :\n          window_user_id= int(time_key[-8:-6]) # extract the user id from window's key\n          window_activity_id=int(time_key[-2:]) # extract the activity id from the windows key\n        elif condition is 'test' :\n          window_user_id= int(time_key[-10:-8]) # extract the user id from window's key\n          window_activity_id= 0\n        else :\n            print(\"Error\")\n            sys.exit()\n            break;\n            \n        ##################################################################################\n        \n        \n        # Time domain - Feature extractor - Part 1. axial(X,Y,Z) Features \n        \n        #[0,1,2] : 't_body_acc_X', 't_body_acc_Y', 't_body_acc_Z'\n        #[3,4,5] : 't_grav_acc_X','t_grav_acc_Y', 't_grav_acc_Z'\n        #[6,7,8] : 't_body_acc_jerk_X','t_body_acc_jerk_Y', 't_body_acc_jerk_Z'\n        #[9,10,11] : 't_body_gyro_X','t_body_gyro_Y', 't_body_gyro_Z'\n        #[12,13,14] : 't_body_gyro_jerk_X', 't_body_gyro_jerk_Y', 't_body_gyro_jerk_Z'\n        \n        axial_columns = time_window.columns[0:15]\n        axial_df = time_window[axial_columns] # X,Y,Z\n        \n        time_axial_features = []\n        \n        for col in range(0,15,3) : \n            EX1=axial_columns[col:col+3]\n            EX2=axial_df[EX1]\n            # ------------------------------------------------------------\n            # 구현 가이드라인\n            # ------------------------------------------------------------\n            # 아래 time_3axial_vector 나타난 Feature를 계산하여야 한다.\n            # 각각을 계산하기위한 함수는 'Feature_engineering.py'에 내제되어 있다.\n            # ------------------------------------------------------------\n            mean_vector=mean_axial(EX2)\n            std_vector=std_axial(EX2)\n            mad_vector=mad_axial(EX2)\n            max_vector=max_axial(EX2)\n            min_vector=min_axial(EX2)\n            sma_value=t_sma_axial(EX2)\n            energy_vector=t_energy_axial(EX2)\n            IQR_vector=IQR_axial(EX2)\n            entropy_vector=entropy_axial(EX2)\n            AR_vector=t_arburg_axial(EX2)\n            corr_vector=t_corr_axial(EX2)\n            # 40 value per each 3-axial signals\n            time_3axial_vector= mean_vector + std_vector + mad_vector + max_vector + min_vector + [sma_value] + energy_vector + IQR_vector + entropy_vector + AR_vector + corr_vector\n            \n            # append these features to the global list of features\n            time_axial_features= time_axial_features+ time_3axial_vector\n        \n        ##################################################################################\n        \n        # Time domain - Feature extractor - Part 2. Magnitude Features \n        \n        #[15]'t_body_acc_mag'\n        #[16]'t_grav_acc_mag'\n        #[17]'t_body_acc_jerk_mag'\n        #[18]'t_body_gyro_mag'\n        #[19]'t_body_gyro_jerk_mag'\n        \n        mag_columns = time_window.columns[15:]\n        mag_columns = time_window[mag_columns]\n        \n        time_mag_features = []\n        \n        for col in mag_columns :\n            \n            # ------------------------------------------------------------\n            # 구현 가이드라인 \n            # ------------------------------------------------------------\n            # 아래 col_mag_values 나타난 Feature를 계산하여야 한다.\n            # 각각을 계산하기위한 함수는 'Feature_engineering.py'에 내제되어 있다.\n            # ------------------------------------------------------------\n            mean_value=mean_mag(mag_columns[col])\n            std_value=std_mag(mag_columns[col])\n            mad_value=mad_mag(mag_columns[col])\n            max_value=max_mag(mag_columns[col])\n            min_value=min_mag(mag_columns[col])\n            sma_value=t_sma_mag(mag_columns[col])\n            energy_value=t_energy_mag(mag_columns[col])\n            IQR_value=IQR_mag(mag_columns[col])\n            entropy_value=entropy_mag(mag_columns[col])\n            AR_vector=t_arburg_mag(mag_columns[col])\n            # 13 value per each t_mag_column\n            col_mag_values = [mean_value, std_value, mad_value, max_value, min_value, sma_value,\n                              energy_value,IQR_value, entropy_value]+ AR_vector\n\n            # col_mag_values will be added to the global list\n            time_mag_features= time_mag_features+ col_mag_values\n\n        \n        ##################################################################################\n        \n        # Frequency domain - Feature extractor - Part 1. axial(X,Y,Z) Features \n        \n        #[0,1,2] : 'f_body_acc_X', 'f_body_acc_Y', 'f_body_acc_Z'\n        #[3,4,5] : 'f_body_acc_jerk_X','f_body_acc_jerk_Y', 'f_body_acc_jerk_Z'\n        #[6,7,8] : 'f_body_gyro_X','f_body_gyro_Y', 'f_body_gyro_Z'\n        #[9,10,11] : 'f_body_gyro_jerk_X','f_body_gyro_jerk_Y', 'f_body_gyro_jerk_Z'\n        \n        axial_columns=freq_window.columns[0:12]\n        axial_df=freq_window[axial_columns]\n        freq_axial_features=[]\n        \n        for col in range(0,12,3) :      \n            test1=axial_columns[col:col+3]\n            EX2=axial_df[test1]\n            # ------------------------------------------------------------\n            # 구현 가이드라인 \n            # ------------------------------------------------------------\n            # 아래 freq_3axial_features 나타난 Feature를 계산하여야 한다.\n            # 각각을 계산하기위한 함수는 'Feature_engineering.py'에 내제되어 있다.\n            # ------------------------------------------------------------\n            mean_vector=mean_axial(EX2)\n            std_vector=std_axial(EX2)\n            mad_vector=mad_axial(EX2)\n            max_vector=f_max_Inds_axial(EX2)\n            min_vector=f_mean_Freq_axial(EX2)\n            sma_value=f_sma_axial(EX2)\n            energy_vector=f_energy_axial(EX2)\n            IQR_vector=IQR_axial(EX2)\n            entropy_vector=entropy_axial(EX2)\n            max_inds_vector=f_max_Inds_axial(EX2)\n            mean_Freq_vector=f_mean_Freq_axial(EX2)\n            skewness_and_kurtosis_vector =f_skewness_and_kurtosis_axial(EX2)\n            #\n            bands_energy_vector=f_all_bands_energy_axial(EX2)\n            \n            \n            freq_3axial_features = mean_vector +std_vector + mad_vector + max_vector + min_vector + [sma_value] + energy_vector + IQR_vector + entropy_vector + max_inds_vector + mean_Freq_vector + skewness_and_kurtosis_vector + bands_energy_vector\n            freq_axial_features = freq_axial_features+ freq_3axial_features\n        \n        ##################################################################################\n        \n        # Frequency domain - Feature extractor - Part 2. Magnitude Features\n        \n        #[12]'f_body_acc_mag'\n        #[13]'f_body_acc_jerk_mag'\n        #[14]'f_body_gyro_mag'\n        #[15]'f_body_gyro_jerk_mag'\n        \n        mag_columns=freq_window.columns[12:]\n        mag_columns=freq_window[mag_columns]\n        \n        freq_mag_features = []\n        \n        for col in mag_columns:\n            # ------------------------------------------------------------\n            # 구현 가이드라인 \n            # ------------------------------------------------------------\n            # 아래 col_mag_values에 나타난 Feature를 계산하여야 한다.\n            # 각각을 계산하기위한 함수는 'Feature_engineering.py'에 내제되어 있다.\n            # ------------------------------------------------------------\n            \n            \n            #\n            mean_value=mean_mag(mag_columns[col])\n            std_value=std_mag(mag_columns[col])\n            mad_value=mad_mag(mag_columns[col])\n            max_value=max_mag(mag_columns[col])\n            min_value=min_mag(mag_columns[col])\n            sma_value=f_sma_mag(mag_columns[col])\n            energy_value=f_energy_mag(mag_columns[col])\n            IQR_value=IQR_mag(mag_columns[col])\n            entropy_value=entropy_mag(mag_columns[col])\n            max_Inds_value=f_max_Inds_mag(mag_columns[col])\n            mean_Freq_value=f_mean_Freq_mag(mag_columns[col])\n            skewness_value=f_skewness_mag(mag_columns[col])\n            kurtosis_value=f_kurtosis_mag(mag_columns[col])\n            # 13 value per each t_mag_column\n            col_mag_values = [mean_value, std_value, mad_value, max_value, \n                              min_value, sma_value, energy_value,IQR_value, \n                              entropy_value, max_Inds_value, mean_Freq_value,\n                              skewness_value, kurtosis_value ]\n            \n            freq_mag_features= freq_mag_features+ col_mag_values\n        \n        ##################################################################################\n        \n        # Time domain - Feature extractor - Part 3. Additional Features \n        \n        additional_features = angle_features(time_window)\n                \n        ##################################################################################\n        \n        total_features = time_axial_features + time_mag_features + freq_axial_features + freq_mag_features + additional_features\n        \n        total_data.append(total_features)\n        if condition is 'train' :\n            total_label.append(window_activity_id)\n    \n    total_data = np.array(total_data)\n    if condition is 'train' :\n        total_label = np.array(total_label)\n    \n    if condition is 'train' :\n        return total_data, total_label\n    elif condition is 'test' :\n        return total_data","metadata":{"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"train_data, train_label = feature_extractor(train_time_dictionary_window,train_frequent_dictionary_window,condition='train')\ntest_data = feature_extractor(test_time_dictionary_window,test_frequent_dictionary_window,condition='test')","metadata":{"trusted":true},"execution_count":40,"outputs":[{"name":"stderr","text":"100%|██████████| 7283/7283 [07:15<00:00, 16.72it/s]\n100%|██████████| 3116/3116 [03:03<00:00, 16.99it/s]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 데이터 정규화","metadata":{}},{"cell_type":"code","source":"# -------------------------------------\n# [Empty Module #2] Data Normalization\n# -------------------------------------\n\n# -------------------------------------\n# Data Normalization\n# -------------------------------------\n# 목적: 앞서 구축한 train,test 셋에 대한 Feature를 정규화한다.\n# 입력인자: train 셋에서 추출된 Feature, test 셋에서 추출된 Feature\n# 출력인자: 정규화된 Feature Vector\n# -------------------------------------\n\n\nfrom sklearn.preprocessing import MinMaxScaler\n\nsc = MinMaxScaler()\n\nM_train_data = sc.fit_transform(train_data)\nM_test_data = sc.transform(test_data)\n\n# ------------------------------------------------------------\n# 구현 가이드라인 \n# ------------------------------------------------------------\n# sklearn에서 제공하는 MinMaxScaler를 사용해 데이터 정규화를 진행한다.\n# (MinMaxScaler가 아닌 다른 정규화를 사용할 수 있다.)\n# ------------------------------------------------------------\n","metadata":{"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"train_label","metadata":{"trusted":true},"execution_count":61,"outputs":[{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"array([5, 5, 5, ..., 2, 2, 2])"},"metadata":{}}]},{"cell_type":"code","source":"len(M_train_data)","metadata":{"trusted":true},"execution_count":58,"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"7283"},"metadata":{}}]},{"cell_type":"code","source":"len(M_test_data)","metadata":{"trusted":true},"execution_count":59,"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"3116"},"metadata":{}}]},{"cell_type":"markdown","source":"## 분류 모델 학습 및 평가","metadata":{}},{"cell_type":"code","source":"# -------------------------------------\n# [Empty Module #3] RandomForest를 이용한 분류\n# -------------------------------------\n\n# -------------------------------------\n# RandomForest를 이용한 분류\n# -------------------------------------\n# 목적: 앞서 완성한 train/test Feature를 RandomForest를 이용해 분류한다.\n# 추가 안내 : 리더보드의 베이스라인은 random_state를 0으로 하였다.\n# 입력인자: Feature vector(train/test)\n# 출력인자: 분류결과\n# -------------------------------------\n\n\n# Min_Max_train_data = sc.fit_transform(train_data)\n# Min_Max_test_data = sc.transform(test_data)\n\nfrom sklearn.ensemble import RandomForestClassifier\nclf = RandomForestClassifier()\nclf.fit(M_train_data, train_label)\nY_pred = clf.predict(M_test_data)\n\n#아잇 왜 안되냐 \n\n# ------------------------------------------------------------\n# 구현 가이드라인 \n# ------------------------------------------------------------\n# sklearn에서 제공하는 RandomForest를 사용해 분류를 진행한다.\n# (RandomForest를가 아닌 다른 분류모델을 사용할 수 있다.)\n# ------------------------------------------------------------","metadata":{"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"submit_csv = pd.read_csv('/kaggle/input/2021-ml-p10/sample_submit.csv')\nsubmit_csv['Label'] = Y_pred\nsubmit_csv['Label'] = submit_csv['Label'].astype(\"int\")\nsubmit_csv.to_csv(\"./result-rf.csv\", index=False)","metadata":{"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}