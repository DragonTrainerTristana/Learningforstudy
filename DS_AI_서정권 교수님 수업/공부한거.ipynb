{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto Gradient Descent for XOR & Linear Regression\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import random as rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 함수 형태 정리 <나올만한 시험 요약>\n",
    "\n",
    "#1번 Gradient 구하는 함수\n",
    "#-----------------------\n",
    "with tf.GradientTape(persistent=True) as tape: # persistent=True는 안에 있는 미분 값을 계속 기억하겠다는 뜻\n",
    "    tf.watch()  \n",
    "    pass\n",
    "X,Y = 0\n",
    "grad = tape.gradient(Y,X)\n",
    "\n",
    "del tape # persistent=True 이므로, 기록을 지우고 싶을때 del tape를 사용한다.\n",
    "\n",
    "# 여기서 x0을 제외한 나머지는 tf.GradientTape() as tape: 로 구할 수 없다. \n",
    "# 오로지, tf.Variable로 만들어진 변수만 적용할 수 있으며, 외부에서 더해지거나 constant값은 처리가 되지 않는다\n",
    "# 하지만 tf.watch(x1), tf.watch(x2), tf.watch(x3)와 같은 함수를 사용한다면 trainable 할 수 있도록 바꾸어진다.\n",
    "x0 = tf.Variable(3.0, name = 'x0')\n",
    "x1 = tf.Variable(3.0, name = 'x1', trainable= False)\n",
    "x2 = tf.Variable(2.0, name = 'x2') + 1.0\n",
    "x3 = tf.constant(3.0, name = 'x3')\n",
    "\n",
    "[var.name for var in tape.watched_variables()] # 현재 tape 상에서 training 가능한 변수를 보여준다.\n",
    "\n",
    "#만약에 아래의 형태 (watched_accessed_variables=False)라면, tape.watch() 함수를 쓰지 않는 변수는 tape.gradient에서 NONE값을 가진다.\n",
    "with tf.GradientTape(watch_accessed_variables=False) as tape:\n",
    "    tape.watch(x0)\n",
    "    pass\n",
    "\n",
    "print(tape.gradient(z, x ,unconnected_gradients = tf.UnconnectedGradients.ZERO))\n",
    "#NONE을 출력하는게 아니라 0을 출력하고 싶을때에\n",
    "#unconnected_gradients = tf.UnconnectedGradients.ZERO // tf.뒤에는 대부분 대문자니까 그걸 기억하기\n",
    "#tf.GradientTape, tf.UnconnectedGradients.ZERO 등\n",
    "#tf.reduce.zero, tf.nn.sigmoid 이런건 제외\n",
    "\n",
    "\n",
    "#2번 차원 감소시켜서 평균 구하는 함수, Loss에 적용해서 풀면 됨\n",
    "#-----------------------\n",
    "tf.reduce_mean() # 예시, tf.reduce_mean(y**2)등\n",
    "\n",
    "#3번 텐서플로우 입력층 형태\n",
    "#-----------------------\n",
    "layer = tf.keras.layers.Dense(2, activation= 'relu') # tf.keras.layers.Dense <- 손코딩해야하니까 외우기\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(6.0, shape=(), dtype=float32)\n",
      "--\n",
      "6.0\n"
     ]
    }
   ],
   "source": [
    "# Tensorflow를 통해 GD를 구하자\n",
    "x = tf.Variable(3.0)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    y = x ** 2\n",
    "grad = tape.gradient(y,x) # y를 x에 대해 미분하고, x값인 3.0을 대입한 값 = dy_dx\n",
    "print(grad) # tf.Tensor 변수로 호출된다.\n",
    "print(\"--\")\n",
    "print(grad.numpy()) # numpy 변수로 바꿔서 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow \n",
    "w = tf.Variable(tf.random.normal((3,2)), name = 'w')\n",
    "b = tf.Variable(tf.zeros(2,dtype=tf.float32), name = 'b')\n",
    "x = [[1.,2.,3.]] # 1., 2., 3. 에서 .는 1.0을 뜻하는데 0을 안써도됨 즉 float 형태로 데이터 만들어주려고 . 붙이는거임\n",
    "print(w)\n",
    "print(b)\n",
    "print(x)\n",
    "\n",
    "print(\"----------------\\n\")\n",
    "\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    y = x @ w + b\n",
    "    loss = tf.reduce_mean(y**2)\n",
    "    \n",
    "print(y)\n",
    "\n",
    "[dL_dw , dL_db] = tape.gradient(loss, [w,b])\n",
    "print(\"----------------OUTPUT----------------\\n\")\n",
    "print(dL_dw)\n",
    "print(dL_db)\n",
    "print(\"\\n\")\n",
    "\n",
    "# 딕셔너리 형태로 gradient 출력하기 \n",
    "my_vars = {'w' : w, 'b' : b}\n",
    "grad = tape.gradient(loss, my_vars)\n",
    "print(grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
      "array([[0., 0.],\n",
      "       [0., 0.],\n",
      "       [0., 0.]], dtype=float32)>, <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0., 0.], dtype=float32)>]\n",
      "--------------\n",
      "\n",
      "dense_3/kernel:0,shape:(3, 2)\n",
      "dense_3/bias:0,shape:(2,)\n"
     ]
    }
   ],
   "source": [
    "# tf.keras.layers.Dense\n",
    "layer = tf.keras.layers.Dense(2, activation='relu')\n",
    "x = tf.constant([[1.,2.,3.]]) # 중요한게, [[]] 이라는거\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    # 순전파\n",
    "    y = layer(x) # y는 layer에 x넣은 output\n",
    "    loss = tf.reduce_mean(y**2) # 이 형태를 기억하자. 이것만 계속 주구장창 나온다.\n",
    "    \n",
    "grad = tape.gradient(loss,layer.trainable_variables) # layer.trainable_variables는 weight, bias니까 자동으로 잡아준다.\n",
    "print(grad)\n",
    "\n",
    "print(\"--------------\\n\")\n",
    "\n",
    "for var, g in zip(layer.trainable_variables, grad):\n",
    "    print(f'{var.name},shape:{g.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(6.0, shape=(), dtype=float32)\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['x0:0']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A trainable variable\n",
    "x0 = tf.Variable(3.0, name='x0')\n",
    "# Not trainable\n",
    "x1 = tf.Variable(3.0, name='x1', trainable=False)\n",
    "# Not a Variable: A variable + tensor returns a tensor.\n",
    "x2 = tf.Variable(2.0, name='x2') + 1.0\n",
    "# Not a variable\n",
    "x3 = tf.constant(3.0, name='x3')\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "  y = (x0**2) + (x1**2) + (x2**2)\n",
    "\n",
    "grad = tape.gradient(y, [x0, x1, x2, x3])\n",
    "\n",
    "for g in grad:\n",
    "  print(g)\n",
    "  \n",
    "[var.name for var in tape.watched_variables()] # tape.watched_variables 기억하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.linspace(-10.0, 10.0, 200+1) # -10부터 10까지, 201개의 index\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(x)\n",
    "    y = tf.nn.sigmoid(x)\n",
    "    \n",
    "    \n",
    "dy_dx = tape.gradient(y,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x,y,label = 'y')\n",
    "\n",
    "plt.plot(x,dy_dx,label = 'dy_dx')\n",
    "plt.legend()\n",
    "_= plt.xlabel('x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResourceVariable : tf.Tensor(1.0, shape=(), dtype=float32)\n",
      "EagerTensor : tf.Tensor(1.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable(2.0)\n",
    "\n",
    "for epoch in range(2):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(x)\n",
    "        y = x + 1\n",
    "    print(type(x).__name__, \":\", tape.gradient(y,x))\n",
    "    x = x + 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 1.  4.]\n",
      " [ 9. 16.]], shape=(2, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 1.  4.]\n",
      " [ 9. 16.]], shape=(2, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[2. 4.]\n",
      " [6. 8.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable([[1.0, 2.0],\n",
    "                 [3.0, 4.0]], dtype=tf.float32)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "  x2 = x**2\n",
    "  print(x2)\n",
    "  # This step is calculated with NumPy\n",
    "  #y = np.mean(x2, axis=0)\n",
    "  #print(y)\n",
    "  # Like most ops, reduce_mean will cast the NumPy array to a constant tensor\n",
    "  # using `tf.convert_to_tensor`.\n",
    "  #y = tf.reduce_mean(y, axis=0)\n",
    "  y = x2\n",
    "  print(y)\n",
    "\n",
    "print(tape.gradient(y, x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LookupError: gradient registry has no entry for: AdjustContrastv2\n"
     ]
    }
   ],
   "source": [
    "image = tf.Variable([[[0.5, 0.0, 0.0]]]) # 얘는 왜 3개노\n",
    "delta = tf.Variable(0.1)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "  new_image = tf.image.adjust_contrast(image, delta)\n",
    "\n",
    "try: # try는 또 뭐노\n",
    "  print(tape.gradient(new_image, [image, delta]))\n",
    "  assert False   # assert는 또 뭐고\n",
    "except LookupError as e: # 얘는 또 뭐고\n",
    "  print(f'{type(e).__name__}: {e}') # 잣됬네\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "tf.Tensor([0. 0.], shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable([2., 2.])\n",
    "y = tf.Variable(3.)\n",
    "\n",
    "with tf.GradientTape(persistent = True) as tape:\n",
    "  z = y**2\n",
    "print(tape.gradient(z, x))\n",
    "print(tape.gradient(z, x ,unconnected_gradients = tf.UnconnectedGradients.ZERO))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf 자동미분을 활용해 선형회귀 문제를 풀어보자 (5월 6일 코드)\n",
    "\n",
    "n = 20\n",
    "\n",
    "x = [[float(i) for i in range(n)]] # 자동미분할때 [] 2개 쓰기\n",
    "y = [[i + np.random.rand()*7 for i in range(n)]]\n",
    "w = tf.Variable(tf.random.normal((1,1)), name = 'w')\n",
    "b = tf.Variable(tf.random.normal((1,1)), name = 'b')\n",
    "\n",
    "iter = 0\n",
    "maxIter = 20\n",
    "lr = tf.constant(0.0005)\n",
    "Loss = []\n",
    "\n",
    "while True:\n",
    "    loss_ = 0.0\n",
    "    \n",
    "    for k in range(np.size(x, 1)):\n",
    "        X = [[x[0][k]]]\n",
    "        Y = [[y[0][k]]]\n",
    "        print(X)\n",
    "    \n",
    "        with tf.GradientTape() as tape:\n",
    "            f = X*w+b\n",
    "            print(\"f\",f)\n",
    "            loss = tf.reduce_mean((f-Y)**2)\n",
    "        \n",
    "        [dl_dw, dl_db] = tape.gradient(loss,[w,b])\n",
    "        #[dl_dw, dl_db] = tape.gradient(loss, trainable_variables) # 얘는 layer가 있을때만\n",
    "        print(\"dl_dw:\", dl_dw)\n",
    "        print(\"dl_dw:\", dl_db)\n",
    "        print(type(dl_dw))\n",
    "        print(type(lr))\n",
    "        loss_ = loss_ + loss\n",
    "        \n",
    "        w.assign_add(-lr*dl_dw)\n",
    "        b.assign_add(-lr*dl_db)\n",
    "        print(w)\n",
    "        print(b) \n",
    "    iter+=1\n",
    "    Loss.append(loss_.numpy())\n",
    "    \n",
    "    w_ = w.numpy()\n",
    "    b_ = b.numpy()\n",
    "    \n",
    "    print(w_[0][0])\n",
    "    print(b_[0][0])\n",
    "    y_regress = [w_[0][0]*i + b_[0][0] for i in x[0]]\n",
    "    print(y_regress)\n",
    "        \n",
    "    if iter>maxIter:break\n",
    "plt.plot(range(iter),Loss,'b')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(x[0],y_regress,'r')\n",
    "plt.scatter(x,y,color ='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf 자동미분을 활용해 선형회귀 문제를 풀어보자 (5월 6일 코드)\n",
    "\n",
    "n = 20\n",
    "\n",
    "x = [[float(i) for i in range(n)]] # 자동미분할때 [] 2개 쓰기\n",
    "y = [[i + np.random.rand()*7 for i in range(n)]]\n",
    "w = tf.Variable(tf.random.normal((1,1)), name = 'w')\n",
    "b = tf.Variable(tf.random.normal((1,1)), name = 'b')\n",
    "\n",
    "iter = 0\n",
    "maxIter = 20\n",
    "lr = tf.constant(0.0005)\n",
    "Loss = []\n",
    "\n",
    "while True:\n",
    "    loss_ = 0.0\n",
    "    \n",
    "    for k in range(np.size(x, 1)):\n",
    "        X = [[x[0][k]]]\n",
    "        Y = [[y[0][k]]]\n",
    "        print(X)\n",
    "    \n",
    "        with tf.GradientTape() as tape:\n",
    "            f = X*w+b\n",
    "            print(\"f\",f)\n",
    "            loss = tf.reduce_mean((f-Y)**2)\n",
    "        \n",
    "        [dl_dw, dl_db] = tape.gradient(loss,[w,b])\n",
    "        #[dl_dw, dl_db] = tape.gradient(loss, trainable_variables) # 얘는 layer가 있을때만\n",
    "        print(\"dl_dw:\", dl_dw)\n",
    "        print(\"dl_dw:\", dl_db)\n",
    "        print(type(dl_dw))\n",
    "        print(type(lr))\n",
    "        loss_ = loss_ + loss\n",
    "        \n",
    "        w.assign_add(-lr*dl_dw)\n",
    "        b.assign_add(-lr*dl_db)\n",
    "        print(w)\n",
    "        print(b) \n",
    "    iter+=1\n",
    "    Loss.append(loss_.numpy())\n",
    "    \n",
    "    w_ = w.numpy()\n",
    "    b_ = b.numpy()\n",
    "    \n",
    "    print(w_[0][0])\n",
    "    print(b_[0][0])\n",
    "    y_regress = [w_[0][0]*i + b_[0][0] for i in x[0]]\n",
    "    print(y_regress)\n",
    "        \n",
    "    if iter>maxIter:break\n",
    "plt.plot(range(iter),Loss,'b')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(x[0],y_regress,'r')\n",
    "plt.scatter(x,y,color ='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#라이브러리 암기하기 손코딩이라 쒯\n",
    "from sklearn import datasets\n",
    "from tensorflow.keras.utils import to_categorical # One-hot encoding\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Activation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "X_tn = np.array([[1, 0], [0, 1], [0, 0], [1, 1]])\n",
    "\n",
    "y_tn = np.array([[1], [1], [0], [0]])\n",
    "\n",
    "epo = 3000\n",
    "n_feat = X_tn.shape[1]\n",
    "n_class = y_tn.shape[1]\n",
    "\n",
    "print(n_feat)\n",
    "print(n_class)\n",
    "print(X_tn.shape)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=n_feat)) # 처음 input은 2개임\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(n_class)) # 최종적으로는 1개를 추출해야함\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'sgd', metrics = ['accuracy'])\n",
    "print(model.predict(X_tn))\n",
    "\n",
    "epoch = np.arange(1, epo+1)\n",
    "accuarcy = hist.history['accuracy']\n",
    "loss = hist.history['loss']\n",
    "\n",
    "# 정확도 학습 그래프\n",
    "plt.plot(epoch, accuracy, label='accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 손실 그래프\n",
    "plt.plot(epoch, loss,'r', label='loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(1)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, BatchNormalization\n",
    "\n",
    "X_tn = np.array([[1,0],[0,1],[0,0],[1,1]]) # shape = 4,2\n",
    "Y_tn = np.array([[1],[1],[0],[0]]) # shape = 4,1\n",
    "\n",
    "n_feat = X_tn.shape[1] # 2\n",
    "n_class = Y_tn.shape[1] # 1\n",
    "\n",
    "epo = 3000\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim = n_feat))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(n_class))\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'sgd', metrics = ['accuracy'])\n",
    "hist = model.fit(X_tn,Y_tn,epochs = epo, batch_size = 1)\n",
    "\n",
    "epoch = np.arange(1,epo+1)\n",
    "accuracy = hist.history['accuracy'] \n",
    "loss = hist.history['loss'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "x_data = np.array([[0,0], [0,1], [1,0], [1,1]], dtype=np.float32)\n",
    "y_data = np.array([[0],   [1],   [1],   [0]], dtype=np.float32)\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([2,2]), name=\"weight1\")\n",
    "b1 = tf.Variable(tf.random_normal([2]), name=\"bias1\")\n",
    "layer1 = tf.sigmoid(tf.matmul(X, W1) + b1) # 행렬 곱/ sigmoid니까 logistic_regression\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([2,1]), name=\"weight2\")\n",
    "b2 = tf.Variable(tf.random_normal([1]), name=\"bias2\")\n",
    "hypothesis = tf.sigmoid(tf.matmul(layer1, W2) + b2)\n",
    "\n",
    "# cost function / minimize cost\n",
    "# cost = -tf.reduce_mean(Y*tf.log(hypothesis) + (1-Y)*tf.log(1-hypothesis))\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))\n",
    "# train = tf.train.GradientDescentOptimizer(learning_rate = 0.1).minimize(cost)\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    " \n",
    "# predicate / accuracy \n",
    "# tf.cast -> True면 1출력, 아니면 0출력 (boolean형태임)\n",
    "predicated = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "# accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted,Y), dtype=tf.float32))\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicated, Y), dtype=tf.float32))\n",
    "\n",
    "with tf.Session() as sess: # 연산과정을 알고 싶을때.\n",
    "    sess.run(tf.global_variables_initializer()) # 변수 초기화임\n",
    "    for step in range(10001):\n",
    "        sess.run(train, feed_dict={X: x_data, Y: y_data})\n",
    "        if step%1000 == 0:\n",
    "            print(step, sess.run(cost, feed_dict={X: x_data, Y: y_data}), sess.run([W1, W2]))\n",
    "    h, c, a = sess.run([hypothesis, predicated, accuracy], feed_dict={X: x_data, Y: y_data})\n",
    "    print(\"\\nHypothesis: \",h,\"\\nCorrect: \",c,\"\\nAccuracy: \",a)\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import tensorflow.compat.v1 as tf\n",
    "#tf.disable_v2_behavior()\n",
    "\n",
    "x = np.array([[0,0], [0,1], [1,0], [1,1]], dtype=np.float32)\n",
    "y = np.array([[0],   [1],   [1],   [0]], dtype=np.float32)\n",
    "\n",
    "W1 = tf.Variable(tf.random.normal([2,2]), name=\"weight1\")\n",
    "b1 = tf.Variable(tf.random.normal([2]), name=\"bias1\")\n",
    "#layer1 = tf.sigmoid(tf.matmul(x, W1) + b1)\n",
    " \n",
    "W2 = tf.Variable(tf.random.normal([2,1]), name=\"weight2\")\n",
    "b2 = tf.Variable(tf.random.normal([1]), name=\"bias2\")\n",
    "#hypothesis = tf.sigmoid(tf.matmul(layer1, W2) + b2)\n",
    "\n",
    "iter = 0\n",
    "stop_iter = 10000\n",
    "lr = tf.constant(0.1, name = 'alpha')\n",
    "Loss = []\n",
    "\n",
    "while True:\n",
    "    \n",
    "    loss_ = 0\n",
    "    for k in range(np.size(x,0)):\n",
    "        X = [x[k]]\n",
    "        Y = [x[k]]\n",
    "        with tf.GradientTape() as tape:\n",
    "            #tf.watch(X)\n",
    "            layer1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "            hypothesis = tf.sigmoid(tf.matmul(layer1,W2)+b2)\n",
    "            loss = tf.reduce_mean((hypothesis - Y)**2)\n",
    "            \n",
    "        [dl_dw1, dl_dw2, dl_db1, dl_db2] = tape.gradient(loss,[W1,W2,b1,b2])    \n",
    "     \n",
    "        loss_ = loss_ + loss\n",
    "        W1.assign_add(-alpha_*dl_dw1)\n",
    "        b1.assign_add(-alpha_*dl_db1)\n",
    "        W2.assign_add(-alpha_*dl_dw2)\n",
    "        b2.assign_add(-alpha_*dl_db2)\n",
    "        \n",
    "    iter += 1\n",
    "    Loss.append(loss_.numpy())\n",
    "    \n",
    "    y_estimate = []\n",
    "    \n",
    "    for k in range(np.sizes(x,0)):\n",
    "        X = [x[0][k]]\n",
    "        layer1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "        hypothesis = tf.sigmoid(tf.matmul(layer1, W2) + b2)\n",
    "        y_estimate.append(hypothesis.numpy())        \n",
    "    \n",
    "    if iter_%1000 == 0:\n",
    "        plt.plot(range(iter_),Loss,'b')\n",
    "        plt.show()\n",
    "        print(f\"y:{y}\")\n",
    "        print(f\"estimate of y:{y_estimate}\")    \n",
    "        print(\"==================================\")\n",
    "    \n",
    "    if iter > stop_iter : break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
